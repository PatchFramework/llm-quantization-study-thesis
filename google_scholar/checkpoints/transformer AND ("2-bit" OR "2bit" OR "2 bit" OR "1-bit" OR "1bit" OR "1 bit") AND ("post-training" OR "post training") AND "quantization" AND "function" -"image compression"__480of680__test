[48, [{"title": "Revisit and Benchmarking of Automated Quantization Towards Fair Comparison", "title_link": "https://ieeexplore.ieee.org/abstract/document/10252023/", "id": "6xUaCz6M4yMJ", "cited_by_count": 0}, {"title": "STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs", "title_link": "https://arxiv.org/abs/2408.01803", "id": "I-GrDevJ2WMJ", "cited_by_count": 0}, {"title": "IM-Unpack: Training and Inference with Arbitrarily Low Precision Integers", "title_link": "https://arxiv.org/abs/2403.07339", "id": "W8FU9K4RPCIJ", "cited_by_count": 1}, {"title": "LQER: Low-Rank Quantization Error Reconstruction for LLMs", "title_link": "https://arxiv.org/abs/2402.02446", "id": "GqWbB--3GScJ", "cited_by_count": 5}, {"title": "Quantized sparse training: A unified trainable framework for joint pruning and quantization in DNNs", "title_link": "https://dl.acm.org/doi/abs/10.1145/3524066", "id": "bDpY3eKEXBYJ", "cited_by_count": 10}, {"title": "Revisiting Block-based Quantisation: What is Important for Sub-8-bit LLM Inference?", "title_link": "https://arxiv.org/abs/2310.05079", "id": "v1-mXoHU68IJ", "cited_by_count": 4}, {"title": "LCQ: Low-Rank Codebook based Quantization for Large Language Models", "title_link": "https://arxiv.org/abs/2405.20973", "id": "pRXMyxh77x0J", "cited_by_count": 1}, {"title": "AdaNF: Quantization Group Adaptive NormalFloat for Low Bit Fine-tuning of LLMs", "title_link": "https://openreview.net/forum?id=nH7k4BkmcX", "id": "-uIOtpNyJE0J", "cited_by_count": 0}, {"title": "FlexRound: Learnable Rounding by Element-wise Division for Post-Training Quantization", "title_link": "https://openreview.net/forum?id=-tYCaP0phY_", "id": "FfcFToOW764J", "cited_by_count": 0}, {"title": "Differentiable Soft Min-Max Loss to Restrict Weight Range for Model Quantization", "title_link": "https://openreview.net/forum?id=ytPyPIypM6", "id": "3awie4MBYIAJ", "cited_by_count": 0}, {"title": "Forget and Rewire: Enhancing the Resilience of Transformer-based Models against {Bit-Flip} Attacks", "title_link": "https://www.usenix.org/conference/usenixsecurity24/presentation/nazari", "id": "xVAM9PVaF1kJ", "cited_by_count": 0}, {"title": "Lut-gemm: Quantized matrix multiplication based on luts for efficient inference in large-scale generative language models", "title_link": "https://arxiv.org/abs/2206.09557", "id": "zwplhYAy3psJ", "cited_by_count": 96}, {"title": "PB-LLM: Partially Binarized Large Language Models", "title_link": "https://openreview.net/forum?id=BifeBRhikU", "id": "6SwEmqzWKLwJ", "cited_by_count": 1}, {"title": "Mitigating the impact of outlier channels for language model quantization with activation regularization", "title_link": "https://arxiv.org/abs/2404.03605", "id": "kzFAGeZF30gJ", "cited_by_count": 3}, {"title": "[PDF][PDF] QuantEase: Optimization-based Quantization for Language Models-An Efficient and Intuitive Algorithm", "title_link": "https://www.researchgate.net/profile/Kayhan-Behdin/publication/373685425_QuantEase_Optimization-based_Quantization_for_Language_Models_-_An_Efficient_and_Intuitive_Algorithm/links/64f88bdff160f748d6d16c80/QuantEase-Optimization-based-Quantization-for-Language-Models-An-Efficient-and-Intuitive-Algorithm.pdf", "id": "fkDEGQyPiMoJ", "cited_by_count": 9}, {"title": "Low-Bitwidth Floating Point Quantization for Efficient High-Quality Diffusion Models", "title_link": "https://arxiv.org/abs/2408.06995", "id": "nhtWSXtfxYwJ", "cited_by_count": 0}, {"title": "Revisiting the parameter efficiency of adapters from the perspective of precision redundancy", "title_link": "http://openaccess.thecvf.com/content/ICCV2023/html/Jie_Revisiting_the_Parameter_Efficiency_of_Adapters_from_the_Perspective_of_ICCV_2023_paper.html", "id": "Veq3mAkAmIEJ", "cited_by_count": 22}, {"title": "BitNet B1. 58 Reloaded: State-of-the-Art Performance Also on Smaller Networks", "title_link": "https://link.springer.com/chapter/10.1007/978-3-031-66705-3_20", "id": "BsMWBLoru-wJ", "cited_by_count": 0}, {"title": "One-shot model for mixed-precision quantization", "title_link": "http://openaccess.thecvf.com/content/CVPR2023/html/Koryakovskiy_One-Shot_Model_for_Mixed-Precision_Quantization_CVPR_2023_paper.html", "id": "6FkK5D9A8SsJ", "cited_by_count": 13}, {"title": "KV Cache is 1 Bit Per Channel: Efficient Large Language Model Inference with Coupled Quantization", "title_link": "https://arxiv.org/abs/2405.03917", "id": "KemNGS09R_gJ", "cited_by_count": 9}, {"title": "ABQ-LLM: Arbitrary-Bit Quantized Inference Acceleration for Large Language Models", "title_link": "https://arxiv.org/abs/2408.08554", "id": "DUBj_it78BIJ", "cited_by_count": 0}, {"title": "BinaryFormer: A Hierarchical-Adaptive Binary Vision Transformer (ViT) for Efficient Computing", "title_link": "https://ieeexplore.ieee.org/abstract/document/10531134/", "id": "pxpDrw6f7QEJ", "cited_by_count": 0}, {"title": "Mixture of Scales: Memory-Efficient Token-Adaptive Binarization for Large Language Models", "title_link": "https://arxiv.org/abs/2406.12311", "id": "tiWugOj1anEJ", "cited_by_count": 1}, {"title": "Token-scaled logit distillation for ternary weight generative language models", "title_link": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/8342218a4ec08b8c19661725e9cd6c0b-Abstract-Conference.html", "id": "Dl7p0RzIH14J", "cited_by_count": 11}, {"title": "Pb-llm: Partially binarized large language models", "title_link": "https://arxiv.org/abs/2310.00034", "id": "mZnxHQtv7VcJ", "cited_by_count": 29}, {"title": "MICSim: A Modular Simulator for Mixed-signal Compute-in-Memory based AI Accelerator", "title_link": "https://arxiv.org/abs/2409.14838", "id": "YTH8jx3iTOAJ", "cited_by_count": 0}, {"title": "Q-S5: Towards Quantized State Space Models", "title_link": "https://arxiv.org/abs/2406.09477", "id": "SYT78S70fHQJ", "cited_by_count": 3}, {"title": "BiViT: Exploring Binary Vision Transformers", "title_link": "https://openreview.net/forum?id=lXBzOtKn20t", "id": "oDq8d1j3RygJ", "cited_by_count": 0}, {"title": "Fisher-aware Quantization for DETR Detectors with Critical-category Objectives", "title_link": "https://arxiv.org/abs/2407.03442", "id": "5zA5k8TYbMkJ", "cited_by_count": 0}, {"title": "[PDF][PDF] Accelerated Segmentation with Mixed-Precision Quantization of EfficientViT-SAM", "title_link": "https://lup.lub.lu.se/luur/download?func=downloadFile&recordOId=9174462&fileOId=9174463", "id": "lo3IewWTW8sJ", "cited_by_count": 0}, {"title": "Unlocking Data-free Low-bit Quantization with Matrix Decomposition for KV Cache Compression", "title_link": "https://arxiv.org/abs/2405.12591", "id": "LuON7nW_FkgJ", "cited_by_count": 2}, {"title": "Compressing large neural networks: Algorithms, systems and scaling laws", "title_link": "https://research-explorer.ista.ac.at/record/17485", "id": "so3tKkmM_kkJ", "cited_by_count": 0}, {"title": "Unified Scaling-Based Pure-Integer Quantization for Low-Power Accelerator of Complex CNNs", "title_link": "https://www.mdpi.com/2079-9292/12/12/2660", "id": "H7_d2tn7-8MJ", "cited_by_count": 2}, {"title": "TernaryLLM: Ternarized Large Language Model", "title_link": "https://arxiv.org/abs/2406.07177", "id": "EyAfc0nW464J", "cited_by_count": 2}, {"title": "More is Less\u2013Byte-quantized models are faster than bit-quantized models on the edge", "title_link": "https://ieeexplore.ieee.org/abstract/document/10020437/", "id": "_aJGehIJAXEJ", "cited_by_count": 1}, {"title": "Pyramid Vector Quantization for LLMs", "title_link": "https://arxiv.org/abs/2410.16926", "id": "bnIutiywAEgJ", "cited_by_count": 0}, {"title": "TerDiT: Ternary Diffusion Models with Transformers", "title_link": "https://arxiv.org/abs/2405.14854", "id": "aP8Lyo95OwkJ", "cited_by_count": 0}, {"title": "Channel-Wise Mixed-Precision Quantization for Large Language Models", "title_link": "https://arxiv.org/abs/2410.13056", "id": "v7dTTvVrVCwJ", "cited_by_count": 0}, {"title": "SliM-LLM: Salience-Driven Mixed-Precision Quantization for Large Language Models", "title_link": "https://arxiv.org/abs/2405.14917", "id": "Sa24Yr7tHswJ", "cited_by_count": 3}, {"title": "USM-Lite: Quantization and Sparsity Aware Fine-Tuning for Speech Recognition with Universal Speech Models", "title_link": "https://ieeexplore.ieee.org/abstract/document/10448217/", "id": "cqUpAWMQO8oJ", "cited_by_count": 3}, {"title": "Accurate lora-finetuning quantization of llms via information retention", "title_link": "https://arxiv.org/abs/2402.05445", "id": "n9_1W7Mc-xAJ", "cited_by_count": 25}, {"title": "ZipCache: Accurate and Efficient KV Cache Quantization with Salient Token Identification", "title_link": "https://arxiv.org/abs/2405.14256", "id": "0wKnyPeFiagJ", "cited_by_count": 6}, {"title": "Searching Optimal Floating-Point Format for Sub-8-Bit Large Language Model Inference", "title_link": "https://ieeexplore.ieee.org/abstract/document/10457111/", "id": "x9H4G_cr8PUJ", "cited_by_count": 0}, {"title": "Vitality: Unifying low-rank and sparse approximation for vision transformer acceleration with a linear taylor attention", "title_link": "https://ieeexplore.ieee.org/abstract/document/10071081/", "id": "e-AVqsA405sJ", "cited_by_count": 39}, {"title": "Kvquant: Towards 10 million context length llm inference with kv cache quantization", "title_link": "https://arxiv.org/abs/2401.18079", "id": "hXjqeDdnmXIJ", "cited_by_count": 16}, {"title": "Tender: Accelerating Large Language Models via Tensor Decomposition and Runtime Requantization", "title_link": "https://arxiv.org/abs/2406.12930", "id": "kNNwLR3ICIYJ", "cited_by_count": 3}, {"title": "Progressive Gradient Flow for Robust N: M Sparsity Training in Transformers", "title_link": "https://arxiv.org/abs/2402.04744", "id": "1wQ2EmsqtEUJ", "cited_by_count": 3}, {"title": "INT-FlashAttention: Enabling Flash Attention for INT8 Quantization", "title_link": "https://arxiv.org/abs/2409.16997", "id": "VzYlG6OoG5YJ", "cited_by_count": 0}, {"title": "SOLE: Hardware-Software Co-design of Softmax and LayerNorm for Efficient Transformer Inference", "title_link": "https://ieeexplore.ieee.org/abstract/document/10323725/", "id": "3-aPdgWUz-8J", "cited_by_count": 4}, {"title": "Toward efficient low-precision training: Data format optimization and hysteresis quantization", "title_link": "https://openreview.net/forum?id=3HJOA-1hb0e", "id": "9wYo_jBpimAJ", "cited_by_count": 9}, {"title": "[PDF][PDF] CodeGPT on XTC", "title_link": "https://repository.tudelft.nl/file/File_47facba4-c909-47e7-bf8a-52cafa7f74ac", "id": "M4K6ZUd4tWkJ", "cited_by_count": 0}, {"title": "Trainable pruned ternary quantization for medical signal classification models", "title_link": "https://www.sciencedirect.com/science/article/pii/S0925231224009871", "id": "L74dymtEyksJ", "cited_by_count": 0}, {"title": "Hardware-Friendly Post-Training Quantization: Input-and Output-Channelwise Scale and Offset", "title_link": "https://openreview.net/forum?id=itJj6p7ssr", "id": "PVosMXZECeoJ", "cited_by_count": 0}, {"title": "An effective post-training embedding binarization approach for fast online top-k passage matching", "title_link": "https://aclanthology.org/2022.aacl-short.14/", "id": "Mf2AuKtnJykJ", "cited_by_count": 10}, {"title": "Fast and Energy-Efficient Inference for Attention-Based Natural Language Processing Models", "title_link": "https://tspace.library.utoronto.ca/handle/1807/128003", "id": "NAlfU77HwuMJ", "cited_by_count": 0}, {"title": "[PDF][PDF] POCA: Post-training Quantization with Temporal Alignment for Codec Avatars", "title_link": "https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05670.pdf", "id": "UWcliiw94jIJ", "cited_by_count": 0}, {"title": "Atalanta: A Bit is Worth a \u201cThousand\u201d Tensor Values", "title_link": "https://dl.acm.org/doi/abs/10.1145/3620665.3640356", "id": "VhTPWOTN-gcJ", "cited_by_count": 2}, {"title": "Efficient quantized sparse matrix operations on tensor cores", "title_link": "https://ieeexplore.ieee.org/abstract/document/10046057/", "id": "CUlHKMkgfAUJ", "cited_by_count": 29}, {"title": "Spiking-Transformer Optimization on FPGA for Image Classification and Captioning", "title_link": "https://ieeexplore.ieee.org/abstract/document/10500284/", "id": "aBbfc2TOiJ4J", "cited_by_count": 1}, {"title": "Resource-Efficient Speech Quality Prediction through Quantization Aware Training and Binary Activation Maps", "title_link": "https://arxiv.org/abs/2407.04578", "id": "SdbZN5zP2oUJ", "cited_by_count": 0}, {"title": "Tapered-Precision Numerical Formats for Deep Learning Inference and Training", "title_link": "https://repository.rit.edu/theses/11621/", "id": "iSQOv3SLta4J", "cited_by_count": 0}, {"title": "Bibert: Accurate fully binarized bert", "title_link": "https://arxiv.org/abs/2203.06390", "id": "220arbo05FAJ", "cited_by_count": 102}, {"title": "Robust and Efficient Quantization-aware Training via Coreset Selection", "title_link": "https://openreview.net/forum?id=4c2pZzG94y", "id": "aV6gW0y5_bEJ", "cited_by_count": 0}, {"title": "Quantization and adversarial robustness of embedded deep neural networks", "title_link": "https://theses.hal.science/tel-04136202/", "id": "ERtRUdrxZlcJ", "cited_by_count": 0}, {"title": "[PDF][PDF] Llm-mq: Mixed-precision quantization for efficient llm deployment", "title_link": "https://www.researchgate.net/profile/Luning-Wang-16/publication/376624532_LLM-MQ_Mixed-precision_Quantization_for_Efficient_LLM_Deployment/links/65818dd43c472d2e8e707515/LLM-MQ-Mixed-precision-Quantization-for-Efficient-LLM-Deployment.pdf", "id": "-1xaj99XrDkJ", "cited_by_count": 8}, {"title": "Quantized Graph Neural Networks for Image Classification", "title_link": "https://www.mdpi.com/2227-7390/11/24/4927", "id": "v05wuA9l_a4J", "cited_by_count": 1}, {"title": "BERT model optimization methods for inference: a comparative study of five alternative BERT-model implementations", "title_link": "https://lutpub.lut.fi/handle/10024/165034", "id": "LawjeET3gJ8J", "cited_by_count": 0}, {"title": "BiSup: Bidirectional Quantization Error Suppression for Large Language Models", "title_link": "https://arxiv.org/abs/2405.15346", "id": "4ZD8EwVbMysJ", "cited_by_count": 0}, {"title": "General Purpose Deep Learning Accelerator Based on Bit Interleaving", "title_link": "https://ieeexplore.ieee.org/abstract/document/10359130/", "id": "T7uLSSwrzhAJ", "cited_by_count": 3}, {"title": "Foundations of Large Language Model Compression--Part 1: Weight Quantization", "title_link": "https://arxiv.org/abs/2409.02026", "id": "9xo8uMUZym4J", "cited_by_count": 0}, {"title": "Model compression and efficient inference for large language models: A survey", "title_link": "https://arxiv.org/abs/2402.09748", "id": "KdnkYWkKlUAJ", "cited_by_count": 16}, {"title": "Evaluating Quantized Large Language Models for Code Generation on Low-Resource Language Benchmarks", "title_link": "https://arxiv.org/abs/2410.14766", "id": "Bc2yRufxiI4J", "cited_by_count": 0}, {"title": "T-mac: Cpu renaissance via table lookup for low-bit llm deployment on edge", "title_link": "https://arxiv.org/abs/2407.00088", "id": "WvHbX4NSLFkJ", "cited_by_count": 2}, {"title": "Unlocking tokens as data points for generalization bounds on larger language models", "title_link": "https://arxiv.org/abs/2407.18158", "id": "dmNdzD0oOscJ", "cited_by_count": 2}, {"title": "Winning both the accuracy of floating point activation and the simplicity of integer arithmetic", "title_link": "https://openreview.net/forum?id=z92lBy1ehjI", "id": "wvOjhQfD3XcJ", "cited_by_count": 3}, {"title": "DUAROT: DUAL ROTATION FOR ADVANCED OUT-LIER MITIGATION IN ROTATED LLMS", "title_link": "https://openreview.net/forum?id=oHBS7R6JcP", "id": "aNjhRSpfTvcJ", "cited_by_count": 0}, {"title": "SKVQ: Sliding-window Key and Value Cache Quantization for Large Language Models", "title_link": "https://arxiv.org/abs/2405.06219", "id": "z2JYVd1WvsUJ", "cited_by_count": 6}, {"title": "CL-Calib: Enhancing Post-training Quantization Calibration through Contrastive Learning", "title_link": "https://openreview.net/forum?id=Wxyyc2vvGd", "id": "uf4SYNJsRT8J", "cited_by_count": 0}, {"title": "Transhash: Transformer-based hamming hashing for efficient image retrieval", "title_link": "https://dl.acm.org/doi/abs/10.1145/3512527.3531405", "id": "NzLBvGCeDrYJ", "cited_by_count": 42}, {"title": "With shared microexponents, a little shifting goes a long way", "title_link": "https://dl.acm.org/doi/abs/10.1145/3579371.3589351", "id": "tB0tY_-g6qQJ", "cited_by_count": 31}, {"title": "Quantized prompt for efficient generalization of vision-language models", "title_link": "https://arxiv.org/abs/2407.10704", "id": "cc5l1AhuD_EJ", "cited_by_count": 1}, {"title": "AutoMPQ: Automatic Mixed-Precision Neural Network Search via Few-Shot Quantization Adapter", "title_link": "https://ieeexplore.ieee.org/abstract/document/10523945/", "id": "haKPRtTpQ1EJ", "cited_by_count": 0}, {"title": "ABS: Accumulation Bit-Width Scaling Method for Designing Low-Precision Tensor Core", "title_link": "https://ieeexplore.ieee.org/abstract/document/10571370/", "id": "ctISmzXYr6oJ", "cited_by_count": 0}, {"title": "ARB-LLM: Alternating Refined Binarizations for Large Language Models", "title_link": "https://arxiv.org/abs/2410.03129", "id": "6e7dBeWYk8oJ", "cited_by_count": 0}, {"title": "[PDF][PDF] Distributional Quantization of Large Language Models", "title_link": "https://www.cee.org/sites/default/files/rsi/Papers/Cholakov_Radostin.pdf", "id": "cmVXGXhkNhEJ", "cited_by_count": 0}, {"title": "The Role of Feature Correlation on Quantized Neural Networks", "title_link": "https://ieeexplore.ieee.org/abstract/document/10389686/", "id": "Z7fSh2vrMCYJ", "cited_by_count": 1}, {"title": "QuantEase: Optimization-based Quantization for Large Language Models", "title_link": "https://openreview.net/forum?id=I07KLz6Em1", "id": "HPFU8CLJdZ0J", "cited_by_count": 0}, {"title": "u-P: The Unit-Scaled Maximal Update Parametrization", "title_link": "https://arxiv.org/abs/2407.17465", "id": "9JFANOfcAhgJ", "cited_by_count": 2}, {"title": "EXAQ: Exponent Aware Quantization For LLMs Acceleration", "title_link": "https://arxiv.org/abs/2410.03185", "id": "ITBKKpSLUyAJ", "cited_by_count": 0}, {"title": "Boost transformer-based language models with gpu-friendly sparsity and quantization", "title_link": "https://aclanthology.org/2023.findings-acl.15/", "id": "dq1G1fBIhJoJ", "cited_by_count": 7}, {"title": "[BUCH][B] Accelerating Attention Models on Hardware", "title_link": "https://escholarship.org/content/qt6d62c22g/qt6d62c22g.pdf", "id": "WtwirfqJrxUJ", "cited_by_count": 0}, {"title": "Accelerating Large Scale Generative AI: A Comprehensive Study", "title_link": "https://search.proquest.com/openview/64bf5127bcbaf0db17974c1b475c9234/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "DHHNShUFL3kJ", "cited_by_count": 0}, {"title": "Fast matrix multiplications for lookup table-quantized llms", "title_link": "https://arxiv.org/abs/2407.10960", "id": "Q1X8zw29RnAJ", "cited_by_count": 1}, {"title": "Uncovering the Hidden Cost of Model Compression", "title_link": "https://openaccess.thecvf.com/content/CVPR2024W/PV/html/Misra_Uncovering_the_Hidden_Cost_of_Model_Compression_CVPRW_2024_paper.html", "id": "5TYlj3t3y0wJ", "cited_by_count": 0}, {"title": "ELSA: Exploiting Layer-wise N: M Sparsity for Vision Transformer Acceleration", "title_link": "https://openaccess.thecvf.com/content/CVPR2024W/ECV24/html/Huang_ELSA_Exploiting_Layer-wise_NM_Sparsity_for_Vision_Transformer_Acceleration_CVPRW_2024_paper.html", "id": "vIoHTRksySMJ", "cited_by_count": 0}, {"title": "[PDF][PDF] Towards Fair and Efficient Distributed Intelligence", "title_link": "https://api.mountainscholar.org/server/api/core/bitstreams/89ba41b0-b714-4214-8133-60e7868827dd/content", "id": "DgHM2GbAHa4J", "cited_by_count": 0}, {"title": "IVQ: In-memory acceleration of DNN inference exploiting varied quantization", "title_link": "https://ieeexplore.ieee.org/abstract/document/9724255/", "id": "W43ntm9oNvUJ", "cited_by_count": 10}, {"title": "DB-LLM: Accurate dual-binarization for efficient LLMs", "title_link": "https://arxiv.org/abs/2402.11960", "id": "QK-4qIOQh5MJ", "cited_by_count": 13}, {"title": "LoQT: Low Rank Adapters for Quantized Training", "title_link": "https://arxiv.org/abs/2405.16528", "id": "D14vvgce__gJ", "cited_by_count": 0}, {"title": "Compressing Large Language Models using Low Rank and Low Precision Decomposition", "title_link": "https://arxiv.org/abs/2405.18886", "id": "d31XIWaPWM4J", "cited_by_count": 3}, {"title": "Torch2Chip: An End-to-end Customizable Deep Neural Network Compression and Deployment Toolkit for Prototype Hardware Accelerator Design", "title_link": "https://proceedings.mlsys.org/paper_files/paper/2024/hash/b8bf2c0dd0b48511889b7d3b2c5fc8f5-Abstract-Conference.html", "id": "4NmTFihevSAJ", "cited_by_count": 0}, {"title": "On-Chip Learning via Transformer In-Context Learning", "title_link": "https://arxiv.org/abs/2410.08711", "id": "7TWm2JfKFicJ", "cited_by_count": 0}, {"title": "OutEffHop: A Principled Outlier-Efficient Attention Layer from Dense Associative Memory Models", "title_link": "https://openreview.net/forum?id=ZCrRCICOkr", "id": "LfdM8DZFLkMJ", "cited_by_count": 0}, {"title": "Any-Precision LLM: Low-Cost Deployment of Multiple, Different-Sized LLMs", "title_link": "https://arxiv.org/abs/2402.10517", "id": "nOF3gaW2hrsJ", "cited_by_count": 4}, {"title": "Bedot: Bit Efficient Dot Product for Deep Generative Models", "title_link": "https://link.springer.com/chapter/10.1007/978-3-031-32180-1_2", "id": "_KJfj4jIzKEJ", "cited_by_count": 0}, {"title": "A Study of Quantisation-aware Training on Time Series Transformer Models for Resource-constrained FPGAs", "title_link": "https://arxiv.org/abs/2310.02654", "id": "ntBR0CgwZbkJ", "cited_by_count": 1}, {"title": "The Tiny Time-series Transformer: Low-latency High-throughput Classification of Astronomical Transients using Deep Model Compression", "title_link": "https://arxiv.org/abs/2303.08951", "id": "2twOftaLC-IJ", "cited_by_count": 2}, {"title": "Efficient signal acquisition and deep learning model compression", "title_link": "https://repositories.lib.utexas.edu/items/d274a838-8cf7-4868-bbbc-9c9036741a41", "id": "z9zCTLV_G5AJ", "cited_by_count": 0}, {"title": "An efficient segmented quantization for graph neural networks", "title_link": "https://link.springer.com/article/10.1007/s42514-022-00121-z", "id": "wfNiCS_sOTMJ", "cited_by_count": 2}, {"title": "OPAL: Outlier-Preserved Microscaling Quantization A ccelerator for Generative Large Language Models", "title_link": "https://arxiv.org/abs/2409.05902", "id": "_mX5Pys2GOMJ", "cited_by_count": 0}, {"title": "Generating Efficient Kernels for Quantized Inference on Large Language Models", "title_link": "https://openreview.net/forum?id=jjazoNAf1S", "id": "Iry2GHEjAswJ", "cited_by_count": 1}, {"title": "QERA: an Analytical Framework for Quantization Error Reconstruction", "title_link": "https://arxiv.org/abs/2410.06040", "id": "yYM2GxIPCtgJ", "cited_by_count": 0}, {"title": "Compensate Quantization Errors+: Quantized Models Are Inquisitive Learners", "title_link": "https://arxiv.org/abs/2407.15508", "id": "RgmbSA4U-q4J", "cited_by_count": 0}, {"title": "Q-dm: An efficient low-bit quantized diffusion model", "title_link": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/f1ee1cca0721de55bb35cf28ab95e1b4-Abstract-Conference.html", "id": "8fMIhKln3hUJ", "cited_by_count": 19}, {"title": "Mixed precision dnn quantization for overlapped speech separation and recognition", "title_link": "https://ieeexplore.ieee.org/abstract/document/9746885/", "id": "yEIi0-pYf2wJ", "cited_by_count": 10}, {"title": "[PDF][PDF] BFP-CIM: Runtime Energy-Accuracy Scalable Computing-in-Memory-Based DNN Accelerator Using Dynamic Block-Floating-Point Arithmetic", "title_link": "https://access.ee.ntu.edu.tw/files/journals/(2024)BFP-CIM_Runtime_Energy-Accuracy_Scalable_Computing-in-Memory-Based_DNN_Accelerator_Using_Dynamic_Block-Floating-Point_Arithmetic.pdf", "id": "JJQISiO3o6sJ", "cited_by_count": 0}, {"title": "Low Resolution Neural Networks", "title_link": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4975898", "id": "Ei8fq8iTcgsJ", "cited_by_count": 0}, {"title": "QT-DoG: Quantization-aware Training for Domain Generalization", "title_link": "https://arxiv.org/abs/2410.06020", "id": "dRDEHE4EPb0J", "cited_by_count": 0}, {"title": "Rotation Invariant Quantization for Model Compression", "title_link": "https://arxiv.org/abs/2303.03106", "id": "3G2bVvm_gYYJ", "cited_by_count": 0}, {"title": "Adaptive Global Power-of-Two Ternary Quantization Algorithm Based on Unfixed Boundary Thresholds", "title_link": "https://www.mdpi.com/1424-8220/24/1/181", "id": "diyqAnCIFJcJ", "cited_by_count": 0}, {"title": "Optimizing neural networks for TinyML: a study on quantization schemes", "title_link": "https://www.politesi.polimi.it/handle/10589/222539", "id": "zwmm1VRe0x8J", "cited_by_count": 0}, {"title": "Adaptive Quantization Error Reconstruction for LLMs with Mixed Precision", "title_link": "https://openreview.net/forum?id=T5pGDydMkS", "id": "HEsuwGHUhS0J", "cited_by_count": 0}, {"title": "DECOUPLE QUANTIZATION STEP AND OUTLIER-MIGRATED RECONSTRUCTION FOR PTQ", "title_link": "https://openreview.net/forum?id=ZtlcdjE1K3", "id": "eoVnvb_O1gAJ", "cited_by_count": 0}, {"title": "Comparative Analysis of Quantization Frameworks: A Deep Learning Perspective: What are Quantization Frameworks in Deep Learning, their Techniques\u00a0\u2026", "title_link": "https://www.diva-portal.org/smash/record.jsf?pid=diva2:1887665", "id": "1HBQ6unKpGQJ", "cited_by_count": 0}, {"title": "Edge-MPQ: Layer-Wise Mixed-Precision Quantization with Tightly Integrated Versatile Inference Units for Edge Computing", "title_link": "https://ieeexplore.ieee.org/abstract/document/10633877/", "id": "FgwbEnMQf8MJ", "cited_by_count": 0}, {"title": "Understanding the potential of fpga-based spatial acceleration for large language model inference", "title_link": "https://dl.acm.org/doi/abs/10.1145/3656177", "id": "p_-Lv1pczqIJ", "cited_by_count": 13}, {"title": "Frame Quantization of Neural Networks", "title_link": "https://arxiv.org/abs/2404.08131", "id": "sGQ3Ucp7DMwJ", "cited_by_count": 0}, {"title": "Investigating the Impact of Quantization on Adversarial Robustness", "title_link": "https://arxiv.org/abs/2404.05639", "id": "E5beiT5-b1YJ", "cited_by_count": 0}, {"title": "Keep the Cost Down: A Review on Methods to Optimize LLM's KV-Cache Consumption", "title_link": "https://arxiv.org/abs/2407.18003", "id": "M3bey3meVIMJ", "cited_by_count": 1}, {"title": "Push Quantization-Aware Training Toward Full Precision Performances via Consistency Regularization", "title_link": "https://arxiv.org/abs/2402.13497", "id": "R0cHqXIVkwsJ", "cited_by_count": 0}, {"title": "big. LITTLE Vision Transformer for Efficient Visual Recognition", "title_link": "https://arxiv.org/abs/2410.10267", "id": "_NNoO4b-g8EJ", "cited_by_count": 0}, {"title": "QCore: Data-efficient, on-device continual calibration for quantized models", "title_link": "https://dl.acm.org/doi/abs/10.14778/3681954.3681957", "id": "KRIxdojFX4oJ", "cited_by_count": 1}, {"title": "ReALLM: A general framework for LLM compression and fine-tuning", "title_link": "https://arxiv.org/abs/2405.13155", "id": "RcsS8PQNqYAJ", "cited_by_count": 0}, {"title": "Certified quantization strategy synthesis for neural networks", "title_link": "https://link.springer.com/chapter/10.1007/978-3-031-71162-6_18", "id": "yRaEFhq0X48J", "cited_by_count": 0}, {"title": "Large Language Model Inference Acceleration: A Comprehensive Hardware Perspective", "title_link": "https://arxiv.org/abs/2410.04466", "id": "QzZvQwY6MrsJ", "cited_by_count": 0}, {"title": "Communication-efficient distributed training of deep neural networks: An algorithms and systems perspective", "title_link": "https://research-explorer.ista.ac.at/record/17490", "id": "3fPrlCN-XfEJ", "cited_by_count": 0}, {"title": "LUTein: Dense-Sparse Bit-Slice Architecture With Radix-4 LUT-Based Slice-Tensor Processing Units", "title_link": "https://ieeexplore.ieee.org/abstract/document/10476468/", "id": "SkaxZxUmkX0J", "cited_by_count": 1}, {"title": "Preliminary: Theories and Algorithms", "title_link": "https://www.taylorfrancis.com/chapters/edit/10.1201/9781003340225-3/preliminary-theories-algorithms-qihua-zhou-peiran-dong", "id": "TwVZMuzVjFMJ", "cited_by_count": 0}, {"title": "MELTing point: Mobile Evaluation of Language Transformers", "title_link": "https://arxiv.org/abs/2403.12844", "id": "zv8OF_NqzXsJ", "cited_by_count": 10}, {"title": "Post-training quantization with low-precision minifloats and integers on FPGAs", "title_link": "https://arxiv.org/abs/2311.12359", "id": "pS_NiFpkx2IJ", "cited_by_count": 2}, {"title": "VitBit: Enhancing Embedded GPU Performance for AI Workloads through Register Operand Packing", "title_link": "https://dl.acm.org/doi/abs/10.1145/3673038.3673045", "id": "0gfu2z4_FfoJ", "cited_by_count": 0}, {"title": "Data-free quantization via mixed-precision compensation without fine-tuning", "title_link": "https://www.sciencedirect.com/science/article/pii/S0031320323004788", "id": "g_0eg-E1-iwJ", "cited_by_count": 15}, {"title": "Edge inference with fully differentiable quantized mixed precision neural networks", "title_link": "https://openaccess.thecvf.com/content/WACV2024/html/Schaefer_Edge_Inference_With_Fully_Differentiable_Quantized_Mixed_Precision_Neural_Networks_WACV_2024_paper.html", "id": "_fihLTuBInAJ", "cited_by_count": 8}, {"title": "HLSTransform: Energy-Efficient Llama 2 Inference on FPGAs Via High Level Synthesis", "title_link": "https://arxiv.org/abs/2405.00738", "id": "kYziL9_7D6gJ", "cited_by_count": 2}, {"title": "Winner-take-all column row sampling for memory efficient adaptation of language model", "title_link": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/0a6059857ae5c82ea9726ee9282a7145-Abstract-Conference.html", "id": "qtd4LmR4r3oJ", "cited_by_count": 14}, {"title": "BFP-CIM: Runtime Energy-Accuracy Scalable Computing-in-Memory-Based DNN Accelerator Using Dynamic Block-Floating-Point Arithmetic", "title_link": "https://ieeexplore.ieee.org/abstract/document/10348028/", "id": "Lp5kNB3JzZ0J", "cited_by_count": 0}, {"title": "LLM-PQ: Serving LLM on Heterogeneous Clusters with Phase-Aware Partition and Adaptive Quantization", "title_link": "https://arxiv.org/abs/2403.01136", "id": "ta-tzvrLbhIJ", "cited_by_count": 6}, {"title": "A comprehensive survey of compression algorithms for language models", "title_link": "https://arxiv.org/abs/2401.15347", "id": "PaxiKGAAjb0J", "cited_by_count": 9}, {"title": "ConSmax: Hardware-Friendly Alternative Softmax with Learnable Parameters", "title_link": "https://arxiv.org/abs/2402.10930", "id": "yomC4WK5a2wJ", "cited_by_count": 1}, {"title": "HTQ: Exploring the High-Dimensional Trade-Off of mixed-precision quantization", "title_link": "https://www.sciencedirect.com/science/article/pii/S0031320324005399", "id": "2FCHQX3j3GUJ", "cited_by_count": 1}, {"title": "2-bit conformer quantization for automatic speech recognition", "title_link": "https://arxiv.org/abs/2305.16619", "id": "oO_V9qewNEMJ", "cited_by_count": 8}, {"title": "Accelerator-aware training for transducer-based speech recognition", "title_link": "https://ieeexplore.ieee.org/abstract/document/10022592/", "id": "ORVW1Rwpj-sJ", "cited_by_count": 1}, {"title": "[PDF][PDF] Techniques and Optimization Strategies for Efficient Hardware Acceleration of Neural Networks: Tap-Wisely-Quantized Winograd Algorithm and Capsule\u00a0\u2026", "title_link": "https://tesidottorato.depositolegale.it/bitstream/20.500.14242/69724/1/conv_latex_thesis.pdf", "id": "OTiHXujVBzoJ", "cited_by_count": 0}, {"title": "QCore: Data-Efficient, On-Device Continual Calibration for Quantized Models--Extended Version", "title_link": "https://arxiv.org/abs/2404.13990", "id": "4E3UBih479cJ", "cited_by_count": 0}, {"title": "[PDF][PDF] Deep Learning Acceleration on Edge Devices with Algorithm/Hardware Co-Design", "title_link": "https://repository.library.northeastern.edu/files/neu:4f186q00m/fulltext.pdf", "id": "b0LFVtI0wsoJ", "cited_by_count": 0}, {"title": "Scalable MatMul-free Language Modeling", "title_link": "https://arxiv.org/abs/2406.02528", "id": "0lryrpFq4N4J", "cited_by_count": 5}, {"title": "Are Conventional SNNs Really Efficient? A Perspective from Network Quantization", "title_link": "http://openaccess.thecvf.com/content/CVPR2024/html/Shen_Are_Conventional_SNNs_Really_Efficient_A_Perspective_from_Network_Quantization_CVPR_2024_paper.html", "id": "KfJoDgEAacEJ", "cited_by_count": 2}, {"title": "Efficient hardware acceleration of deep neural networks via arithmetic complexity reduction", "title_link": "https://upcommons.upc.edu/handle/2117/404668", "id": "9XYBsWMEzm4J", "cited_by_count": 0}, {"title": "[PDF][PDF] Towards Green AI: Assessing the Robustness of Conformer and Transformer Models under Compression", "title_link": "https://eurasip.org/Proceedings/Eusipco/Eusipco2024/pdfs/0000336.pdf", "id": "6mDjWGPQt5UJ", "cited_by_count": 0}, {"title": "ETA: An efficient training accelerator for DNNs based on hardware-algorithm co-optimization", "title_link": "https://ieeexplore.ieee.org/abstract/document/9707608/", "id": "oiPfI4c79fQJ", "cited_by_count": 19}, {"title": "Inferflow: an Efficient and Highly Configurable Inference Engine for Large Language Models", "title_link": "https://arxiv.org/abs/2401.08294", "id": "D6tZfQ_RXW8J", "cited_by_count": 2}, {"title": "FastQuery: Communication-efficient Embedding Table Query for Private LLM Inference", "title_link": "https://arxiv.org/abs/2405.16241", "id": "3Z4NxWd3qPcJ", "cited_by_count": 0}, {"title": "Q-Hitter: A Better Token Oracle for Efficient LLM Inference via Sparse-Quantized KV Cache", "title_link": "https://proceedings.mlsys.org/paper_files/paper/2024/hash/bbb7506579431a85861a05fff048d3e1-Abstract-Conference.html", "id": "Mdiu4RigREkJ", "cited_by_count": 8}, {"title": "PV-Tuning: Beyond Straight-Through Estimation for Extreme LLM Compression", "title_link": "https://arxiv.org/abs/2405.14852", "id": "C4ASQ9GupTgJ", "cited_by_count": 3}, {"title": "Language Models as Zero-shot Lossless Gradient Compressors: Towards General Neural Parameter Prior Models", "title_link": "https://arxiv.org/abs/2409.17836", "id": "DQyZfbpb8CUJ", "cited_by_count": 0}, {"title": "A Review of Posit Arithmetic for Energy-Efficient Computation: Methodologies, Applications, and Challenges", "title_link": "https://link.springer.com/chapter/10.1007/978-3-031-42478-6_24", "id": "VKYa23iVpmAJ", "cited_by_count": 0}, {"title": "BFD: Binarized Frequency-enhanced Distillation for Vision Transformer", "title_link": "https://ieeexplore.ieee.org/abstract/document/10688360/", "id": "OZZEokmjb3EJ", "cited_by_count": 0}, {"title": "FAT: Frequency-aware transformation for bridging full-precision and low-precision deep representations", "title_link": "https://ieeexplore.ieee.org/abstract/document/9837828/", "id": "QO4W70jtVOoJ", "cited_by_count": 3}, {"title": "A Unified View of Delta Parameter Editing in Post-Trained Large-Scale Models", "title_link": "https://arxiv.org/abs/2410.13841", "id": "_c7dHdcT-1cJ", "cited_by_count": 0}, {"title": "Lossless KV Cache Compression to 2%", "title_link": "https://arxiv.org/abs/2410.15252", "id": "M0fOS2iVJNgJ", "cited_by_count": 0}, {"title": "Transformer-based models and hardware acceleration analysis in autonomous driving: A survey", "title_link": "https://arxiv.org/abs/2304.10891", "id": "7SVjf3mCqGEJ", "cited_by_count": 12}, {"title": "MC-MoE: Mixture Compressor for Mixture-of-Experts LLMs Gains More", "title_link": "https://arxiv.org/abs/2410.06270", "id": "xhBN3AhZjpoJ", "cited_by_count": 0}, {"title": "A Survey: Collaborative Hardware and Software Design in the Era of Large Language Models", "title_link": "https://arxiv.org/abs/2410.07265", "id": "ARTFYEP9PBQJ", "cited_by_count": 0}, {"title": "N3h-core: Neuron-designed neural network accelerator via fpga-based heterogeneous computing cores", "title_link": "https://dl.acm.org/doi/abs/10.1145/3490422.3502367", "id": "immwtER3HqAJ", "cited_by_count": 14}, {"title": "[HTML][HTML] QuATON: Quantization Aware Training of Optical Neurons", "title_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10996779/", "id": "07FN8MFC0qMJ", "cited_by_count": 0}, {"title": "Ladder: Enabling Efficient {Low-Precision} Deep Learning Computing through Hardware-aware Tensor Transformation", "title_link": "https://www.usenix.org/conference/osdi24/presentation/wang-lei", "id": "weaVkde-KgAJ", "cited_by_count": 3}, {"title": "Improved model design and training techniques for efficient DNN inference", "title_link": "https://repositories.lib.utexas.edu/items/7b77b6bd-021f-4fcb-9d3e-ffbabd34cce0", "id": "_2yZEyd2jqAJ", "cited_by_count": 0}, {"title": "LightToken: A task and model-agnostic lightweight token embedding framework for pre-trained language models", "title_link": "https://dl.acm.org/doi/abs/10.1145/3580305.3599416", "id": "utCVQ-NOKA0J", "cited_by_count": 4}, {"title": "Parameter-efficient fine-tuning for large models: A comprehensive survey", "title_link": "https://arxiv.org/abs/2403.14608", "id": "-Y8JuxIyxIQJ", "cited_by_count": 119}, {"title": "[PDF][PDF] Assessing Task-Specific Performance Gains from Parameter-Efficient Fine-Tuning of Autoregressive Large Language Models", "title_link": "https://thesis.eur.nl/pub/73000/FV_Thesis_477745pv_MSc.pdf", "id": "i5ZvpuyNk74J", "cited_by_count": 0}, {"title": "Zero-Delay QKV Compression for Mitigating KV Cache and Network Bottlenecks in LLM Inference", "title_link": "https://arxiv.org/abs/2408.04107", "id": "qWms09jKZb4J", "cited_by_count": 0}, {"title": "MPQ-YOLO: Ultra low mixed-precision quantization of YOLO for edge devices deployment", "title_link": "https://www.sciencedirect.com/science/article/pii/S0925231223013334", "id": "5WiRkBRsaysJ", "cited_by_count": 7}, {"title": "Spike Motion: A Spiking Neural Network Framework for Resource Aware Implementation of Spiking Transformer Network on FPGA", "title_link": "https://search.proquest.com/openview/2fcd00f34176b5d739636d70fee2c75f/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "b5b-lqTHq38J", "cited_by_count": 0}, {"title": "Quantized Embedding Vectors for Controllable Diffusion Language Models", "title_link": "https://arxiv.org/abs/2402.10107", "id": "3cZsCA7jhV4J", "cited_by_count": 0}, {"title": "SI-BiViT: Binarizing Vision Transformers with Spatial Interaction", "title_link": "https://openreview.net/forum?id=HacSqd6Yw6", "id": "W0D_s-ju2lAJ", "cited_by_count": 0}, {"title": "Single-path bit sharing for automatic loss-aware model compression", "title_link": "https://ieeexplore.ieee.org/abstract/document/10122994/", "id": "OIwkPrehseoJ", "cited_by_count": 6}, {"title": "Compression and Analysis of Pre-trained Language Model using Neural Slimming", "title_link": "https://uwspace.uwaterloo.ca/handle/10012/18586", "id": "G3aPn7FYdEQJ", "cited_by_count": 0}, {"title": "[PDF][PDF] Semantics-Augmented Quantization-Aware Training for Point Cloud Classification", "title_link": "https://diglib.eg.org/bitstreams/94aeb24c-1cf4-4edc-85f0-98797cb77c81/download", "id": "SvBxX49fLq0J", "cited_by_count": 0}, {"title": "2Bits of Protein: Efficient Protein Language Models at the Scale of 2-bits", "title_link": "https://openreview.net/forum?id=bVQjzz3ABw", "id": "QKAj-ekNkUQJ", "cited_by_count": 0}, {"title": "ME-Switch: A Memory-Efficient Expert Switching Framework for Large Language Models", "title_link": "https://arxiv.org/abs/2406.09041", "id": "TQMC3amakb0J", "cited_by_count": 0}, {"title": "[BUCH][B] Binary Neural Networks: Algorithms, Architectures, and Applications", "title_link": "https://books.google.com/books?hl=de&lr=&id=fqQIEQAAQBAJ&oi=fnd&pg=PP1&dq=transformer+AND+(%222-bit%22+OR+%222bit%22+OR+%222+bit%22+OR+%221-bit%22+OR+%221bit%22+OR+%221+bit%22)+AND+(%22post-training%22+OR+%22post+training%22)+AND+%22quantization%22+AND+%22function%22+-%22image+compression%22&ots=97Vl65JMOz&sig=7_CzzpYZANhPodMwJwMww8u_xVk", "id": "U_JzY1feVZAJ", "cited_by_count": 1}, {"title": "Accessible Foundation Models: Systems, Algorithms, and Science", "title_link": "https://search.proquest.com/openview/6c8dd68b06a47574c371e521806504a7/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "hsZpaXAMD6MJ", "cited_by_count": 0}, {"title": "Dual-discriminator adversarial framework for data-free quantization", "title_link": "https://www.sciencedirect.com/science/article/pii/S0925231222011420", "id": "HHJRfPwonToJ", "cited_by_count": 6}, {"title": "Endor: Hardware-Friendly Sparse Format for Offloaded LLM Inference", "title_link": "https://arxiv.org/abs/2406.11674", "id": "gpRwzM-3vI0J", "cited_by_count": 0}, {"title": "Gear: An efficient kv cache compression recipefor near-lossless generative inference of llm", "title_link": "https://arxiv.org/abs/2403.05527", "id": "h48eVYF__7wJ", "cited_by_count": 33}, {"title": "Structured term pruning for computational efficient neural networks inference", "title_link": "https://ieeexplore.ieee.org/abstract/document/9759473/", "id": "nxSLY9oCLO0J", "cited_by_count": 5}, {"title": "Fast State Restoration in LLM Serving with HCache", "title_link": "https://arxiv.org/abs/2410.05004", "id": "vo-MdRvPuOoJ", "cited_by_count": 1}, {"title": "FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation", "title_link": "https://arxiv.org/abs/2407.07093", "id": "kgmbXuMZJQsJ", "cited_by_count": 0}, {"title": "Reducing the Side-Effects of Oscillations in Training of Quantized YOLO Networks", "title_link": "https://openaccess.thecvf.com/content/WACV2024/html/Gupta_Reducing_the_Side-Effects_of_Oscillations_in_Training_of_Quantized_YOLO_WACV_2024_paper.html", "id": "WD_LSpHMD6sJ", "cited_by_count": 2}, {"title": "SPARK: Scalable and Precision-Aware Acceleration of Neural Networks via Efficient Encoding", "title_link": "https://ieeexplore.ieee.org/abstract/document/10476472/", "id": "UiSB028IBLoJ", "cited_by_count": 6}, {"title": "A low-cost fully integer-based cnn accelerator on fpga for real-time traffic sign recognition", "title_link": "https://ieeexplore.ieee.org/abstract/document/9853508/", "id": "FJK-3HYytaUJ", "cited_by_count": 11}, {"title": "Sharpness-Aware Data Generation for Zero-shot Quantization", "title_link": "https://openreview.net/forum?id=8mKXMnhnFW", "id": "Q5CzJc69AX8J", "cited_by_count": 0}, {"title": "Fast: Dnn training under variable precision block floating point with stochastic rounding", "title_link": "https://ieeexplore.ieee.org/abstract/document/9773221/", "id": "MJZ7IjIZM3oJ", "cited_by_count": 56}, {"title": "Think: Thinner key cache by query-driven pruning", "title_link": "https://arxiv.org/abs/2407.21018", "id": "GFtTSyXTwwwJ", "cited_by_count": 2}, {"title": "Training-Free Activation Sparsity in Large Language Models", "title_link": "https://arxiv.org/abs/2408.14690", "id": "ZtWRVIIuw60J", "cited_by_count": 0}, {"title": "QEBVerif: Quantization error bound verification of neural networks", "title_link": "https://link.springer.com/chapter/10.1007/978-3-031-37703-7_20", "id": "Hla00VOEBfgJ", "cited_by_count": 9}, {"title": "ESPACE: Dimensionality Reduction of Activations for Model Compression", "title_link": "https://arxiv.org/abs/2410.05437", "id": "gjtzFKz1WYcJ", "cited_by_count": 0}, {"title": "Succinct Compression: Lossless Compression for Fast and Memory-Efficient Deep Neural Network Inference", "title_link": "https://openreview.net/forum?id=VNzq9PBFta", "id": "dY7H2pxqePIJ", "cited_by_count": 0}, {"title": "PSQ: An Automatic Search Framework for Data-Free Quantization on PIM-based Architecture", "title_link": "https://ieeexplore.ieee.org/abstract/document/10361000/", "id": "yVJXewpTnRUJ", "cited_by_count": 1}, {"title": "Inference Optimization of Foundation Models on AI Accelerators", "title_link": "https://dl.acm.org/doi/abs/10.1145/3637528.3671465", "id": "QN6H78rWQjwJ", "cited_by_count": 0}, {"title": "Outliers and Calibration Sets have Diminishing Effect on Quantization of Modern LLMs", "title_link": "https://arxiv.org/abs/2405.20835", "id": "_r0GcG7HThsJ", "cited_by_count": 2}, {"title": "BOLD: Boolean Logic Deep Learning", "title_link": "https://arxiv.org/abs/2405.16339", "id": "Dvy2lOOr8NUJ", "cited_by_count": 0}, {"title": "Self-distilled quantization: Achieving high compression rates in transformer-based language models", "title_link": "https://arxiv.org/abs/2307.05972", "id": "f9wtJqzpgSsJ", "cited_by_count": 2}, {"title": "Pruning large language models with semi-structural adaptive sparse training", "title_link": "https://arxiv.org/abs/2407.20584", "id": "DsaR8xKxEmsJ", "cited_by_count": 1}, {"title": "[HTML][HTML] Accelerating and Compressing Transformer-Based PLMs for Enhanced Comprehension of Computer Terminology", "title_link": "https://www.mdpi.com/1999-5903/16/11/385", "id": "S0_Ys2oxNb0J", "cited_by_count": 0}, {"title": "Efficient Processing of Convolutional Neural Networks on the Edge: A Hybrid Approach Using Hardware Acceleration and Dual-Teacher Compression", "title_link": "https://stars.library.ucf.edu/etd2023/321/", "id": "64RsPfLheRYJ", "cited_by_count": 0}, {"title": "Smart-DNN+: A Memory-efficient Neural Networks Compression Framework for the Model Inference", "title_link": "https://dl.acm.org/doi/abs/10.1145/3617688", "id": "WjGHVusCDx8J", "cited_by_count": 1}, {"title": "Joint Pruning and Channel-wise Mixed-Precision Quantization for Efficient Deep Neural Networks", "title_link": "https://ieeexplore.ieee.org/abstract/document/10644100/", "id": "Y1gVaiagBGoJ", "cited_by_count": 0}, {"title": "LLM-Codebook for Extreme Compression of Large Language Models", "title_link": "https://openreview.net/forum?id=nMbWsXPUVL", "id": "ELO24GAK0GMJ", "cited_by_count": 0}, {"title": "Foldgpt: Simple and effective large language model compression scheme", "title_link": "https://arxiv.org/abs/2407.00928", "id": "uXo_PnuyVaIJ", "cited_by_count": 1}, {"title": "Swift: a scalable lightweight infrastructure for fine-tuning", "title_link": "https://arxiv.org/abs/2408.05517", "id": "qI3F_km6biQJ", "cited_by_count": 2}, {"title": "Does your LLM truly unlearn? An embarrassingly simple approach to recover unlearned knowledge", "title_link": "https://arxiv.org/abs/2410.16454", "id": "hmvlD7GUQMEJ", "cited_by_count": 0}, {"title": "Variation-aware vision transformer quantization", "title_link": "https://arxiv.org/abs/2307.00331", "id": "BIjxgeV3y7kJ", "cited_by_count": 11}, {"title": "Hardware-Efficient Quantization for Green Custom Foundation Models", "title_link": "https://openreview.net/forum?id=NODACmWFNJ", "id": "F_4wTncq5J0J", "cited_by_count": 0}, {"title": "A Comprehensive Survey on Recent Model Compression and Acceleration Approaches for Deep Neural Networks and Transformers", "title_link": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4893335", "id": "0ZzpDGZAPwUJ", "cited_by_count": 0}, {"title": "MoDeGPT: Modular Decomposition for Large Language Model Compression", "title_link": "https://arxiv.org/abs/2408.09632", "id": "YS7l0sbVsf8J", "cited_by_count": 0}, {"title": "Beyond Linear Approximations: A Novel Pruning Approach for Attention Matrix", "title_link": "https://arxiv.org/abs/2410.11261", "id": "ocbdG0Sx63wJ", "cited_by_count": 0}, {"title": "SoBS-X: Squeeze-out bit sparsity for ReRAM-crossbar-based neural network accelerator", "title_link": "https://ieeexplore.ieee.org/abstract/document/9769275/", "id": "FFRkQOy1myQJ", "cited_by_count": 6}, {"title": "Table-Lookup MAC: Scalable Processing of Quantised Neural Networks in FPGA Soft Logic", "title_link": "https://dl.acm.org/doi/abs/10.1145/3626202.3637576", "id": "F_mrCbxU9bYJ", "cited_by_count": 0}, {"title": "Exploiting Neural-Network Statistics for Low-Power DNN Inference", "title_link": "https://ieeexplore.ieee.org/abstract/document/10498075/", "id": "_h_DYXYaxfgJ", "cited_by_count": 0}, {"title": "CSKV: Training-Efficient Channel Shrinking for KV Cache in Long-Context Scenarios", "title_link": "https://arxiv.org/abs/2409.10593", "id": "0vJ9rMLBZcYJ", "cited_by_count": 0}, {"title": "Applying maximum entropy principle on quantized neural networks correlates with high accuracy", "title_link": "https://hal.science/hal-04409740/", "id": "LDiSIdxbyS4J", "cited_by_count": 0}, {"title": "Training of Physical Neural Networks", "title_link": "https://arxiv.org/abs/2406.03372", "id": "eVK7HX_ajiEJ", "cited_by_count": 2}, {"title": "[PDF][PDF] End-to-End Neural Network Compression via \u21131", "title_link": "https://openaccess.thecvf.com/content/CVPR2024W/MAI/supplemental/Nasery_End-to-End_Neural_Network_CVPRW_2024_supplemental.pdf", "id": "OfPMzBl2B14J", "cited_by_count": 0}, {"title": "INT-FP-QSim: Mixed Precision and Formats For Large Language Models and Vision Transformers", "title_link": "https://arxiv.org/abs/2307.03712", "id": "DbTjMQbP7pUJ", "cited_by_count": 1}, {"title": "Sparse finetuning for inference acceleration of large language models", "title_link": "https://arxiv.org/abs/2310.06927", "id": "aZjhI5RBJBIJ", "cited_by_count": 12}, {"title": "Rand: Robustness aware norm decay for quantized seq2seq models", "title_link": "https://arxiv.org/abs/2305.15536", "id": "10NEyXXlT_EJ", "cited_by_count": 4}, {"title": "Efficient speech representation learning with low-bit quantization", "title_link": "https://arxiv.org/abs/2301.00652", "id": "N_phVgfQRtEJ", "cited_by_count": 6}, {"title": "Improving post-training quantization on object detection with task loss-guided lp metric", "title_link": "https://arxiv.org/abs/2304.09785", "id": "O9Znp7vidR8J", "cited_by_count": 1}, {"title": "[PDF][PDF] A Comparative Study of PEFT Approaches for Language Models of Code", "title_link": "https://helda.helsinki.fi/bitstreams/75b4256c-009a-4cf2-bf84-798a6127dfaf/download", "id": "H20nOP6zooMJ", "cited_by_count": 0}, {"title": "Computational complexity optimization of neural network-based equalizers in digital signal processing: a comprehensive approach", "title_link": "https://ieeexplore.ieee.org/abstract/document/10496171/", "id": "yiLIEAapB9QJ", "cited_by_count": 14}, {"title": "Flexible Residual Binarization for Image Super-Resolution", "title_link": "https://openreview.net/forum?id=zji9DLksTz", "id": "ukxNarN_px4J", "cited_by_count": 2}, {"title": "Binarydm: Towards accurate binarization of diffusion model", "title_link": "https://arxiv.org/abs/2404.05662", "id": "bTWx9cuX9a8J", "cited_by_count": 4}, {"title": "A Comprehensive Approach Towards Wheat Leaf Disease Identification Leveraging Transformer Models and Federated Learning", "title_link": "https://ieeexplore.ieee.org/abstract/document/10623136/", "id": "fpsB3flQgBsJ", "cited_by_count": 0}, {"title": "OpenBA-V2: Reaching 77.3% High Compression Ratio with Fast Multi-Stage Pruning", "title_link": "https://arxiv.org/abs/2405.05957", "id": "RLa1KmA4T-UJ", "cited_by_count": 1}, {"title": "FinerCut: Finer-grained Interpretable Layer Pruning for Large Language Models", "title_link": "https://arxiv.org/abs/2405.18218", "id": "2lH8fSS9cZAJ", "cited_by_count": 2}, {"title": "Cbq: Cross-block quantization for large language models", "title_link": "https://arxiv.org/abs/2312.07950", "id": "SYs6WXFmxT0J", "cited_by_count": 6}, {"title": "A survey of quantization methods for efficient neural network inference", "title_link": "https://www.taylorfrancis.com/chapters/edit/10.1201/9781003162810-13/survey-quantization-methods-efficient-neural-network-inference-amir-gholami-sehoon-kim-zhen-dong-zhewei-yao-michael-mahoney-kurt-keutzer", "id": "Qqkb0h3nbzYJ", "cited_by_count": 1169}, {"title": "Zeroquant (4+ 2): Redefining llms quantization with a new fp6-centric strategy for diverse generative tasks", "title_link": "https://arxiv.org/abs/2312.08583", "id": "Crhvmi5S_jYJ", "cited_by_count": 5}, {"title": "Survey on Computer Vision Techniques for Internet-of-Things Devices", "title_link": "https://ieeexplore.ieee.org/abstract/document/10205899/", "id": "Vq-zJD9dqesJ", "cited_by_count": 2}, {"title": "MultiQuant: A Novel Multi-Branch Topology Method for Arbitrary Bit-width Network Quantization", "title_link": "https://arxiv.org/abs/2305.08117", "id": "3MnH99Uc0iYJ", "cited_by_count": 2}, {"title": "Understanding and improving knowledge distillation for quantization-aware training of large transformer encoders", "title_link": "https://arxiv.org/abs/2211.11014", "id": "zeh2Hqs3FugJ", "cited_by_count": 8}, {"title": "MiniCache: KV Cache Compression in Depth Dimension for Large Language Models", "title_link": "https://arxiv.org/abs/2405.14366", "id": "yt6lkpf21PoJ", "cited_by_count": 12}, {"title": "Timestep-Aware Correction for Quantized Diffusion Models", "title_link": "https://arxiv.org/abs/2407.03917", "id": "EF2CboHURTQJ", "cited_by_count": 0}, {"title": "Enhancing computation efficiency in large language models through weight and activation quantization", "title_link": "https://arxiv.org/abs/2311.05161", "id": "omL03houD9YJ", "cited_by_count": 7}, {"title": "Progressive Mixed-Precision Decoding for Efficient LLM Inference", "title_link": "https://arxiv.org/abs/2410.13461", "id": "tUWP0rhRyzAJ", "cited_by_count": 0}, {"title": "GIFT-SW: Gaussian noise Injected Fine-Tuning of Salient Weights for LLMs", "title_link": "https://arxiv.org/abs/2408.15300", "id": "Xm7eRRv19VEJ", "cited_by_count": 1}, {"title": "BTR: Binary Token Representations for Efficient Retrieval Augmented Language Models", "title_link": "https://arxiv.org/abs/2310.01329", "id": "k3gjiKwsdcQJ", "cited_by_count": 2}, {"title": "Fast inference of mixture-of-experts language models with offloading", "title_link": "https://arxiv.org/abs/2312.17238", "id": "vw4Of67TQm0J", "cited_by_count": 12}, {"title": "Boosting Binary Neural Networks via Dynamic Thresholds Learning", "title_link": "https://arxiv.org/abs/2211.02292", "id": "4kzYfhp5M8QJ", "cited_by_count": 0}, {"title": "Logic and arithmetic computation-in-memory accelerators: Based on memristor devices", "title_link": "https://research.tudelft.nl/en/publications/logic-and-arithmetic-computation-in-memory-accelerators-based-on-", "id": "SjDrlrVdFIUJ", "cited_by_count": 0}, {"title": "[HTML][HTML] Computer vision model compression techniques for embedded systems: A survey", "title_link": "https://www.sciencedirect.com/science/article/pii/S009784932400150X", "id": "THaJ1DHUhgsJ", "cited_by_count": 0}, {"title": "Error-aware Quantization through Noise Tempering", "title_link": "https://arxiv.org/abs/2212.05603", "id": "_xoxnmEHaoQJ", "cited_by_count": 2}, {"title": "PalmBench: A Comprehensive Benchmark of Compressed Large Language Models on Mobile Platforms", "title_link": "https://arxiv.org/abs/2410.05315", "id": "4kpjXUf7jGsJ", "cited_by_count": 0}, {"title": "Efficient quantization-aware training with adaptive coreset selection", "title_link": "https://arxiv.org/abs/2306.07215", "id": "3clBJGFJ98gJ", "cited_by_count": 11}, {"title": "Quantization of Neural Networks", "title_link": "https://link.springer.com/chapter/10.1007/978-981-99-5068-3_4", "id": "0pZz4qVJiCMJ", "cited_by_count": 0}, {"title": "Interpolating Video-LLMs: Toward Longer-sequence LMMs in a Training-free Manner", "title_link": "https://arxiv.org/abs/2409.12963", "id": "XvCn6Edkw_sJ", "cited_by_count": 0}, {"title": "[PDF][PDF] SpQuant-SNN: ultra-low precision membrane potential with sparse activations unlock the potential of on-device spiking neural networks applications", "title_link": "https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2024.1440000/pdf?isPublishedV2=true", "id": "zPyiO9dFp8EJ", "cited_by_count": 0}, {"title": "Mobile edge intelligence for large language models: A contemporary survey", "title_link": "https://arxiv.org/abs/2407.18921", "id": "1EpY2uQEhdEJ", "cited_by_count": 7}, {"title": "A survey on efficient inference for large language models", "title_link": "https://arxiv.org/abs/2404.14294", "id": "duKqwDtsssQJ", "cited_by_count": 35}, {"title": "Embedding Compression in Recommender Systems: A Survey", "title_link": "https://dl.acm.org/doi/abs/10.1145/3637841", "id": "03GY_2749LoJ", "cited_by_count": 10}, {"title": "Binary and ternary natural language generation", "title_link": "https://arxiv.org/abs/2306.01841", "id": "dZNx6aOYwGIJ", "cited_by_count": 7}, {"title": "Hardware Support for Trustworthy Machine Learning: A Survey", "title_link": "https://ieeexplore.ieee.org/abstract/document/10528373/", "id": "zI5VAY1_FJgJ", "cited_by_count": 0}, {"title": "Deeploy: Enabling Energy-Efficient Deployment of Small Language Models On Heterogeneous Microcontrollers", "title_link": "https://arxiv.org/abs/2408.04413", "id": "riYJuv6tSr8J", "cited_by_count": 1}, {"title": "[HTML][HTML] LSTM Gate Disclosure as an Embedded AI Methodology for Wearable Fall-Detection Sensors", "title_link": "https://www.mdpi.com/2073-8994/16/10/1296", "id": "WvGjMk-9MnEJ", "cited_by_count": 0}, {"title": "Device-edge digital semantic communication with trained non-linear quantization", "title_link": "https://ieeexplore.ieee.org/abstract/document/10200355/", "id": "mrIk6HW9xTwJ", "cited_by_count": 7}, {"title": "Mixed-Precision Quantization with Cross-Layer Dependencies", "title_link": "https://arxiv.org/abs/2307.05657", "id": "441YCDntx8QJ", "cited_by_count": 2}, {"title": "Lq-lora: Low-rank plus quantized matrix decomposition for efficient language model finetuning", "title_link": "https://arxiv.org/abs/2311.12023", "id": "UCbBoC51mxkJ", "cited_by_count": 30}, {"title": "Efficient and effective methods for mixed precision neural network quantization for faster, energy-efficient inference", "title_link": "https://arxiv.org/abs/2301.13330", "id": "x66_pmVo_fMJ", "cited_by_count": 8}, {"title": "Llm inference unveiled: Survey and roofline model insights", "title_link": "https://arxiv.org/abs/2402.16363", "id": "u4RfTVhKko0J", "cited_by_count": 30}, {"title": "Overviewing AI-Dedicated Hardware for On-Device AI in Smartphones", "title_link": "https://link.springer.com/chapter/10.1007/978-3-031-22170-5_4", "id": "PU0Dib320zYJ", "cited_by_count": 3}, {"title": "Comparative Study: Standalone IEEE 16-bit Floating-Point for Image Classification", "title_link": "https://arxiv.org/abs/2305.10947", "id": "_3SBanAY-b4J", "cited_by_count": 1}, {"title": "Approximate computing and the efficient machine learning expedition", "title_link": "https://dl.acm.org/doi/abs/10.1145/3508352.3561105", "id": "iGUlUFY8hVAJ", "cited_by_count": 13}, {"title": "Neural Network Compression Using Binarization and Few Full-Precision Weights", "title_link": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4927691", "id": "lHv2EoN3woUJ", "cited_by_count": 0}, {"title": "Auto Tuning Quantized Graph Neural Networks on GPU Tensor Core via TVM", "title_link": "https://ieeexplore.ieee.org/abstract/document/10456077/", "id": "ijscYxxH3UEJ", "cited_by_count": 0}, {"title": "A Review of State-of-the-Art Mixed-Precision Neural Network Frameworks", "title_link": "https://ieeexplore.ieee.org/abstract/document/10509805/", "id": "ZnTVbznLZ9MJ", "cited_by_count": 3}, {"title": "A survey of computationally efficient graph neural networks for reconfigurable systems", "title_link": "https://www.mdpi.com/2078-2489/15/7/377", "id": "sXxnhonaGMYJ", "cited_by_count": 1}, {"title": "[BUCH][B] RRAM Compute-in-Memory Hardware for Efficient, Versatile, and Accurate ai Inference", "title_link": "https://search.proquest.com/openview/4b2d442d248410e80abe6f44e4952273/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "nPd0v6zhT0UJ", "cited_by_count": 0}, {"title": "A Survey of Model Compression and Its Feedback Mechanism in Federated Learning", "title_link": "https://dl.acm.org/doi/abs/10.1145/3643488.3660293", "id": "ymslhLU2XQsJ", "cited_by_count": 0}, {"title": "[PDF][PDF] Training High-performance Spiking Neural Networks Through Reducing Quantization Error", "title_link": "https://practical-dl.github.io/2022/short_paper/19.pdf", "id": "EdbMKBEdYYQJ", "cited_by_count": 0}, {"title": "Efficient methods for deep learning", "title_link": "https://www.sciencedirect.com/science/article/pii/B9780128221099000138", "id": "p0E7bYf3gwkJ", "cited_by_count": 9}, {"title": "Enable deep learning on mobile devices: Methods, systems, and applications", "title_link": "https://dl.acm.org/doi/abs/10.1145/3486618", "id": "B5HXaxbAB_cJ", "cited_by_count": 103}, {"title": "Odg-q: Robust quantization via online domain generalization", "title_link": "https://ieeexplore.ieee.org/abstract/document/9956164/", "id": "BAcFD7nixkMJ", "cited_by_count": 1}, {"title": "[PDF][PDF] Energy-Efficient AI on EDGE", "title_link": "https://www.researchgate.net/profile/Prasham-Sheth/publication/370471083_Energy-Efficient_AI_on_EDGE/links/6451f90a97449a0e1a741b3c/Energy-Efficient-AI-on-EDGE.pdf", "id": "Mbhr1998BEIJ", "cited_by_count": 0}, {"title": "Software Optimization and Design Methodology for Low Power Computer Vision Systems", "title_link": "https://dl.acm.org/doi/abs/10.1145/3687310", "id": "Dml28GAMpoIJ", "cited_by_count": 0}, {"title": "VcLLM: Video Codecs are Secretly Tensor Codecs", "title_link": "https://arxiv.org/abs/2407.00467", "id": "qf2xcgkTxecJ", "cited_by_count": 0}, {"title": "EvoPress: Towards Optimal Dynamic Model Compression via Evolutionary Search", "title_link": "https://arxiv.org/abs/2410.14649", "id": "vyV_REOckVwJ", "cited_by_count": 0}, {"title": "Towards Light-Weight and High Performance Speech Enhancement and Recognition Using Mixed Precision Neural Network Quantization", "title_link": "https://search.proquest.com/openview/ba60e85ee8e3ece25e8f18db2822dbcb/1?pq-origsite=gscholar&cbl=2026366&diss=y", "id": "-4zGJtKB1B4J", "cited_by_count": 0}, {"title": "Bringing AI to edge: From deep learning's perspective", "title_link": "https://www.sciencedirect.com/science/article/pii/S0925231221016428", "id": "xG3kTPM2dMkJ", "cited_by_count": 130}, {"title": "Fast and Low-Cost Approximate Multiplier for FPGAs using Dynamic Reconfiguration", "title_link": "https://arxiv.org/abs/2310.10053", "id": "oDElByoWeHMJ", "cited_by_count": 0}, {"title": "RBNN: memory-efficient reconfigurable deep binary neural network with IP protection for Internet of things", "title_link": "https://ieeexplore.ieee.org/abstract/document/9852785/", "id": "Ce0lEe-ODmgJ", "cited_by_count": 8}, {"title": "Deploying deep learning networks based advanced techniques for image processing on FPGA platform", "title_link": "https://link.springer.com/article/10.1007/s00521-023-08718-3", "id": "LafzqVmPE9oJ", "cited_by_count": 7}, {"title": "A survey of resource-efficient llm and multimodal foundation models", "title_link": "https://arxiv.org/abs/2401.08092", "id": "5sm8TgDYkeIJ", "cited_by_count": 57}, {"title": "SpaLLM: Unified Compressive Adaptation of Large Language Models with Sketching", "title_link": "https://arxiv.org/abs/2410.06364", "id": "9hVx8UGEtzQJ", "cited_by_count": 0}, {"title": "DyRecMul: Fast and Low-Cost Approximate Multiplier for FPGAs using Dynamic Reconfiguration", "title_link": "https://dl.acm.org/doi/abs/10.1145/3663480", "id": "3y6zI-NVGVwJ", "cited_by_count": 1}, {"title": "QIGen: Generating Efficient Kernels for Quantized Inference on Large Language Models", "title_link": "https://arxiv.org/abs/2307.03738", "id": "238E_n0elMoJ", "cited_by_count": 3}, {"title": "On-device language models: A comprehensive review", "title_link": "https://arxiv.org/abs/2409.00088", "id": "eItQJPAiF9QJ", "cited_by_count": 3}, {"title": "A survey of model compression strategies for object detection", "title_link": "https://link.springer.com/article/10.1007/s11042-023-17192-x", "id": "9VzRJdEYraAJ", "cited_by_count": 17}, {"title": "Efficient large language models: A survey", "title_link": "https://arxiv.org/abs/2312.03863", "id": "ok-1VecpDZMJ", "cited_by_count": 83}, {"title": "Join the high accuracy club on imagenet with a binary neural network ticket", "title_link": "https://arxiv.org/abs/2211.12933", "id": "M_mFdJIlJQIJ", "cited_by_count": 20}, {"title": "Highly accurate and fast YOLOv4-Based polyp detection", "title_link": "https://www.sciencedirect.com/science/article/pii/S0957417423013362", "id": "OB9Fq2rCOQMJ", "cited_by_count": 17}, {"title": "Ternary Singular Value Decomposition as a Better Parameterized Form in Linear Mapping", "title_link": "https://arxiv.org/abs/2308.07641", "id": "7okIU4C6HZ8J", "cited_by_count": 2}, {"title": "Light-weight visualvoice: Neural network quantization on audio visual speech separation", "title_link": "https://ieeexplore.ieee.org/abstract/document/10193263/", "id": "redKcvL8HYkJ", "cited_by_count": 5}, {"title": "Efficient Deep Learning Models for Edge IOT Devices-A Review", "title_link": "https://www.techrxiv.org/doi/full/10.36227/techrxiv.172254372.21002541", "id": "y0ILMKpaP8kJ", "cited_by_count": 0}, {"title": "INTERPOLATING VIDEO-LLMS: TOWARD LONGER", "title_link": "https://openreview.net/forum?id=QrTvFCa4nX", "id": "VdKNPbLKSboJ", "cited_by_count": 0}, {"title": "Apple intelligence foundation language models", "title_link": "https://arxiv.org/abs/2407.21075", "id": "xXeIKWO4ddAJ", "cited_by_count": 10}, {"title": "CRPIM: An efficient compute-reuse scheme for ReRAM-based Processing-in-Memory DNN accelerators", "title_link": "https://www.sciencedirect.com/science/article/pii/S1383762124001292", "id": "TlxXeden_sgJ", "cited_by_count": 0}, {"title": "SpikeLM: Towards General Spike-Driven Language Modeling via Elastic Bi-Spiking Mechanisms", "title_link": "https://arxiv.org/abs/2406.03287", "id": "rZqdPQm32QAJ", "cited_by_count": 4}, {"title": "MobileNMT: Enabling Translation in 15MB and 30ms", "title_link": "https://arxiv.org/abs/2306.04235", "id": "X-1ino6pF30J", "cited_by_count": 1}, {"title": "Hardware approximate techniques for deep neural network accelerators: A survey", "title_link": "https://dl.acm.org/doi/abs/10.1145/3527156", "id": "X7-Fu3D9-GQJ", "cited_by_count": 97}, {"title": "Block-Wise Mixed-Precision Quantization: Enabling High Efficiency for Practical ReRAM-based DNN Accelerators", "title_link": "https://arxiv.org/abs/2310.12182", "id": "5GX_HsuXvxAJ", "cited_by_count": 1}, {"title": "Llm as a system service on mobile devices", "title_link": "https://arxiv.org/abs/2403.11805", "id": "n2yLM788Q2YJ", "cited_by_count": 15}, {"title": "LLM Adaptation and Utilization", "title_link": "https://link.springer.com/content/pdf/10.1007/978-3-031-65647-7_4.pdf", "id": "U1_LLsCav0kJ", "cited_by_count": 0}, {"title": "Locret: Enhancing Eviction in Long-Context LLM Inference with Trained Retaining Heads", "title_link": "https://arxiv.org/abs/2410.01805", "id": "NHhqj4VLjmcJ", "cited_by_count": 0}, {"title": "Towards accurate binary neural networks via modeling contextual dependencies", "title_link": "https://link.springer.com/chapter/10.1007/978-3-031-20083-0_32", "id": "A51nMypeclgJ", "cited_by_count": 9}, {"title": "Seed-TTS: A Family of High-Quality Versatile Speech Generation Models", "title_link": "https://arxiv.org/abs/2406.02430", "id": "zmNRS52SFCEJ", "cited_by_count": 23}, {"title": "Edgemoe: Fast on-device inference of moe-based large language models", "title_link": "https://arxiv.org/abs/2308.14352", "id": "EfiwOPmNFeUJ", "cited_by_count": 39}, {"title": "Achieving Peak Performance for Large Language Models: A Systematic Review", "title_link": "https://ieeexplore.ieee.org/abstract/document/10589417/", "id": "9JggUy0XtccJ", "cited_by_count": 0}, {"title": "Structured pruning for efficient generative pre-trained language models", "title_link": "https://aclanthology.org/2023.findings-acl.692/", "id": "gPQjRmtOVH0J", "cited_by_count": 23}, {"title": "Fpga-based deep learning inference accelerators: Where are we standing?", "title_link": "https://dl.acm.org/doi/abs/10.1145/3613963", "id": "sTFKipU3-gwJ", "cited_by_count": 12}, {"title": "Sparsification of deep neural networks via ternary quantization", "title_link": "https://webthesis.biblio.polito.it/29424/", "id": "pIJB6hMaTKIJ", "cited_by_count": 0}, {"title": "Utilization of local large language models for business applications", "title_link": "https://aaltodoc.aalto.fi/items/01e2845d-07fc-4748-8258-2e526592b202", "id": "yaq8_ncYtysJ", "cited_by_count": 3}, {"title": "[PDF][PDF] Efficient Classification of Aircraft Marshalling Signs with FMCW Radar", "title_link": "https://research.tue.nl/files/333629567/Vermunt_J.pdf", "id": "-em6-JBFgh8J", "cited_by_count": 0}, {"title": "[HTML][HTML] 7 \u03bcJ/inference end-to-end gesture recognition from dynamic vision sensor data using ternarized hybrid convolutional neural networks", "title_link": "https://www.sciencedirect.com/science/article/pii/S0167739X23002704", "id": "20t2HbW_AnwJ", "cited_by_count": 6}, {"title": "Model compression methods for YOLOv5: A review", "title_link": "https://arxiv.org/abs/2307.11904", "id": "axQvxDEz7CoJ", "cited_by_count": 14}, {"title": "Plinio: a user-friendly library of gradient-based methods for complexity-aware DNN optimization", "title_link": "https://ieeexplore.ieee.org/abstract/document/10272045/", "id": "47IxJ2lugFEJ", "cited_by_count": 10}, {"title": "Pruning vs XNOR-Net: A comprehensive study of deep learning for audio classification on edge-devices", "title_link": "https://ieeexplore.ieee.org/abstract/document/9672158/", "id": "Q6kOy9yc65QJ", "cited_by_count": 21}, {"title": "Edge enhanced network monitoring using TinyML", "title_link": "https://oulurepo.oulu.fi/handle/10024/51084", "id": "dJxm8UQJidgJ", "cited_by_count": 0}, {"title": "Constrained deep learning for MEMS sensors-based applications", "title_link": "https://theses.hal.science/tel-04363136/", "id": "l5Vm4MlaYX4J", "cited_by_count": 0}, {"title": "Towards Optimization-Friendly Binary Neural Network", "title_link": "https://openreview.net/forum?id=4Hq816XDDG", "id": "se-0_sUnjOQJ", "cited_by_count": 0}, {"title": "Palu: Compressing KV-Cache with Low-Rank Projection", "title_link": "https://arxiv.org/abs/2407.21118", "id": "uNZd63PX67kJ", "cited_by_count": 0}, {"title": "Efficient Implementation of Activation Function on FPGA for Accelerating Neural Networks", "title_link": "https://ieeexplore.ieee.org/abstract/document/10181406/", "id": "jjWrQdSpKcAJ", "cited_by_count": 0}, {"title": "[PDF][PDF] Performance Analysis and Comparison of Quantized Language Models on Resource Constraints-The Case of Supply Chain Risk Data.", "title_link": "https://www.researchgate.net/profile/Chuka-Uzo/publication/384144893_Performance_Analysis_and_Comparison_of_Quantized_Language_Models_on_Resource_Constraints_-The_Case_of_Supply_Chain_Risk_Data/links/66f16e1efc6cc46489705e53/Performance-Analysis-and-Comparison-of-Quantized-Language-Models-on-Resource-Constraints-The-Case-of-Supply-Chain-Risk-Data.pdf", "id": "oGOJFfoZNBQJ", "cited_by_count": 0}, {"title": "[PDF][PDF] Speeding up Semantic History Compression in Reinforcement Learning", "title_link": "https://epub.jku.at/obvulihs/content/titleinfo/10242755/full.pdf", "id": "CI4BQRNUZH4J", "cited_by_count": 0}, {"title": "Efficient Artificial Intelligence with Novel Matrix Transformations and Homomorphic Encryption", "title_link": "https://ieeexplore.ieee.org/abstract/document/10689665/", "id": "dBZVj7U39jwJ", "cited_by_count": 0}, {"title": "[HTML][HTML] Hardware Acceleration and Approximation of CNN Computations: Case Study on an Integer Version of LeNet", "title_link": "https://www.mdpi.com/2079-9292/13/14/2709", "id": "1D9Wkw3wZiMJ", "cited_by_count": 0}, {"title": "SpecExec: Massively Parallel Speculative Decoding for Interactive LLM Inference on Consumer Devices", "title_link": "https://arxiv.org/abs/2406.02532", "id": "8vE7-caqvp0J", "cited_by_count": 2}, {"title": "Cambricon-LLM: A Chiplet-Based Hybrid Architecture for On-Device Inference of 70B LLM", "title_link": "https://arxiv.org/abs/2409.15654", "id": "XHKD0m_mKKAJ", "cited_by_count": 1}, {"title": "Ultra-low Precision Multiplication-free Training for Deep Neural Networks", "title_link": "https://arxiv.org/abs/2302.14458", "id": "NJ3HHvB9ihkJ", "cited_by_count": 1}, {"title": "Zeroth-Order Fine-Tuning of LLMs with Extreme Sparsity", "title_link": "https://arxiv.org/abs/2406.02913", "id": "XZCwz7ctHIMJ", "cited_by_count": 0}, {"title": "[PDF][PDF] Low-Cost Language Models: Survey and Performance Evaluation on Python Code Generation Jessica L\u00f3pez Espejel, Mahaman Sanoussi Yahaya Alassan\u00a0\u2026", "title_link": "https://www.researchgate.net/profile/Jessica-Lopez-Espejel/publication/380074496_Low-Cost_Language_Models_Survey_and_Performance_Evaluation_on_Python_Code_Generation/links/66d5c723fa5e11512c47d2c0/Low-Cost-Language-Models-Survey-and-Performance-Evaluation-on-Python-Code-Generation.pdf", "id": "SeBppPJQjPkJ", "cited_by_count": 0}, {"title": "Robust and Energy Efficient Deep Learning Systems", "title_link": "https://repositum.tuwien.at/handle/20.500.12708/197559", "id": "5YJrGH37V18J", "cited_by_count": 0}, {"title": "Improving and Automating Machine Learning Model Compression", "title_link": "https://keep.lib.asu.edu/items/193384", "id": "OMSAQjb_IsEJ", "cited_by_count": 0}, {"title": "[PDF][PDF] Pruning vs XNOR-Net: A Comprehensive Study on Deep Learning for Audio Classification in Microcontrollers", "title_link": "https://www.academia.edu/download/85868787/2108.06128v1.pdf", "id": "X9dwE730TEkJ", "cited_by_count": 0}, {"title": "Review of lightweight deep convolutional neural networks", "title_link": "https://link.springer.com/article/10.1007/s11831-023-10032-z", "id": "gshYhLSWDz8J", "cited_by_count": 13}, {"title": "Fast matrix multiplication for binary and ternary CNNs on ARM CPU", "title_link": "https://ieeexplore.ieee.org/abstract/document/9956533/", "id": "4XezA_jsc4oJ", "cited_by_count": 4}, {"title": "[PDF][PDF] The efficiency spectrum of large language models: An algorithmic survey", "title_link": "https://www.researchgate.net/profile/Tianyi-Chen-36/publication/376139731_The_Efficiency_Spectrum_of_Large_Language_Models_An_Algorithmic_Survey/links/656b657cb86a1d521b28b422/The-Efficiency-Spectrum-of-Large-Language-Models-An-Algorithmic-Survey.pdf", "id": "04TyF9K2ZDoJ", "cited_by_count": 12}, {"title": "Advancements in accelerating deep neural network inference on aiot devices: A survey", "title_link": "https://ieeexplore.ieee.org/abstract/document/10398463/", "id": "WLq0DccPoXEJ", "cited_by_count": 17}, {"title": "Toward Large-scale Spiking Neural Networks: A Comprehensive Survey and Future Directions", "title_link": "https://arxiv.org/abs/2409.02111", "id": "U2bhIX01DZoJ", "cited_by_count": 0}, {"title": "Neuromorphic Vision Chip", "title_link": "https://link.springer.com/chapter/10.1007/978-3-031-11506-6_5", "id": "wxvl34pDkbIJ", "cited_by_count": 0}, {"title": "[HTML][HTML] Adaptive approximate computing in edge AI and IoT applications: A review", "title_link": "https://www.sciencedirect.com/science/article/pii/S1383762124000511", "id": "FxjQT7sdwlsJ", "cited_by_count": 7}, {"title": "Sparsity-Aware Protocol for ZK-friendly ML Models: Shedding Lights on Practical ZKML", "title_link": "https://eprint.iacr.org/2024/1018", "id": "3i-mNW4y8ccJ", "cited_by_count": 0}, {"title": "Code Generation on a Diet: A Comparative Evaluation of Low-Parameter Large Language Models", "title_link": "https://studenttheses.uu.nl/handle/20.500.12932/46906", "id": "769Nr1WlnMkJ", "cited_by_count": 0}, {"title": "[BUCH][B] Generative AI on AWS: Building context-aware multimodal reasoning applications", "title_link": "https://books.google.com/books?hl=de&lr=&id=MOTiEAAAQBAJ&oi=fnd&pg=PT7&dq=transformer+AND+(%222-bit%22+OR+%222bit%22+OR+%222+bit%22+OR+%221-bit%22+OR+%221bit%22+OR+%221+bit%22)+AND+(%22post-training%22+OR+%22post+training%22)+AND+%22quantization%22+AND+%22function%22+-%22image+compression%22&ots=k3qZtl1bxB&sig=DztwF6Edb7Nd8GUyLX4i-VzxVhY", "id": "x6ioE1G0o04J", "cited_by_count": 3}, {"title": "Expert Router: Orchestrating Efficient Language Model Inference through Prompt Classification", "title_link": "https://arxiv.org/abs/2404.15153", "id": "NQcJQxNrhxEJ", "cited_by_count": 0}, {"title": "Fast and Energy-Efficient Inference for Attention-Based Natural Language Processing Models", "title_link": "https://search.proquest.com/openview/8ef0b6a759aff7cf22bf26f40affd1bd/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "s5M7ZBF-Zk4J", "cited_by_count": 0}, {"title": "Layer Ensemble Averaging for Improving Memristor-Based Artificial Neural Network Performance", "title_link": "https://arxiv.org/abs/2404.15621", "id": "-D52YhD7bgYJ", "cited_by_count": 0}, {"title": "Digital-SC: Digital Semantic Communication with Adaptive Network Split and Learned Non-Linear Quantization", "title_link": "https://arxiv.org/abs/2305.13553", "id": "AHE7hdbgvsQJ", "cited_by_count": 3}, {"title": "Acceleration algorithms in gnns: A survey", "title_link": "https://arxiv.org/abs/2405.04114", "id": "lbMoRGvJxXsJ", "cited_by_count": 2}, {"title": "Development and Optimization of a 1-Dimensional Convolutional Neural Network-Based Keyword Spotting Model for FPGA Acceleration", "title_link": "https://scholarworks.gvsu.edu/theses/1129/", "id": "PcZa4FW9XK4J", "cited_by_count": 0}, {"title": "Resource-Efficient Neural Networks for Embedded Systems", "title_link": "https://www.jmlr.org/papers/v25/18-566.html", "id": "Q8trvuThNvkJ", "cited_by_count": 10}, {"title": "Memory-based computing for energy-efficient ai: Grand challenges", "title_link": "https://ieeexplore.ieee.org/abstract/document/10321880/", "id": "7qZd7ilNi7UJ", "cited_by_count": 2}, {"title": "Optimal fine-grained n: M sparsity for activations and neural gradients", "title_link": "https://arxiv.org/abs/2203.10991", "id": "4FisYL7eY_EJ", "cited_by_count": 12}, {"title": "Lightweight Deep Learning for Resource-Constrained Environments: A Survey", "title_link": "https://dl.acm.org/doi/abs/10.1145/3657282", "id": "0U_Cz5RXTUUJ", "cited_by_count": 6}, {"title": "SpikingRx: From Neural to Spiking Receiver", "title_link": "https://arxiv.org/abs/2409.05610", "id": "cfFM8s-Vh6cJ", "cited_by_count": 0}, {"title": "Model compression of deep neural network architectures for visual pattern recognition: Current status and future directions", "title_link": "https://www.sciencedirect.com/science/article/pii/S0045790624001083", "id": "APNWpmW9frgJ", "cited_by_count": 1}, {"title": "A high-performance accelerator for super-resolution processing on embedded GPU", "title_link": "https://ieeexplore.ieee.org/abstract/document/10041020/", "id": "lMza3IxHFZsJ", "cited_by_count": 6}, {"title": "Efficient Multitask Dense Predictor via Binarization", "title_link": "https://openaccess.thecvf.com/content/CVPR2024/html/Shang_Efficient_Multitask_Dense_Predictor_via_Binarization_CVPR_2024_paper.html", "id": "3NyMD9cTUDgJ", "cited_by_count": 0}, {"title": "CNN hardware accelerator for real-time bearing fault diagnosis", "title_link": "https://www.mdpi.com/1424-8220/23/13/5897", "id": "mue5FCGQGI4J", "cited_by_count": 3}, {"title": "SpaceEvo: Searching Hardware-Friendly Search Space for Efficient Int8 Inference", "title_link": "https://openreview.net/forum?id=RsSJ2_M2Nk4", "id": "VWNzWAkRzi8J", "cited_by_count": 0}, {"title": "Marlin: Mixed-precision auto-regressive parallel inference on large language models", "title_link": "https://arxiv.org/abs/2408.11743", "id": "gMoAsB-KgyUJ", "cited_by_count": 2}, {"title": "Software-Hardware Co-Design: Towards Ultimate Efficiency in Deep Learning Acceleration", "title_link": "https://search.proquest.com/openview/913cca707a0bf3e5557756f302e70a02/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "VmLuStfgxocJ", "cited_by_count": 0}, {"title": "A Review of AIoT-based Edge Devices and Lightweight Deployment", "title_link": "https://www.techrxiv.org/doi/full/10.36227/techrxiv.21687248.v2", "id": "qbi28j-fyRsJ", "cited_by_count": 4}, {"title": "Learning Generalizable Mixed-Precision Quantization via Attribution Imitation", "title_link": "https://link.springer.com/article/10.1007/s11263-024-02130-7", "id": "K89njZANH-gJ", "cited_by_count": 1}, {"title": "Energy-efficient time series analysis with machine learning and deep learning on embedded computing platforms", "title_link": "http://amsdottorato.unibo.it/11234/", "id": "HiEDpn9v00kJ", "cited_by_count": 0}, {"title": "Be Like Water: Adaptive Floating Point for Machine Learning", "title_link": "https://proceedings.mlr.press/v162/yeh22a.html", "id": "3JwGSG8b940J", "cited_by_count": 6}, {"title": "SAC: An ultra-efficient spin-based architecture for compressed DNNs", "title_link": "https://dl.acm.org/doi/abs/10.1145/3632957", "id": "11KTQbm6UUoJ", "cited_by_count": 2}, {"title": "Compeft: Compression for communicating parameter efficient updates via sparsification and quantization", "title_link": "https://arxiv.org/abs/2311.13171", "id": "gOvgdcyK40wJ", "cited_by_count": 7}, {"title": "CHESS: Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification", "title_link": "https://arxiv.org/abs/2409.01366", "id": "TiOT6o7V2V0J", "cited_by_count": 0}, {"title": "Computational complexity evaluation of neural network applications in signal processing", "title_link": "https://arxiv.org/abs/2206.12191", "id": "nnhhRThRJ-4J", "cited_by_count": 50}, {"title": "[PDF][PDF] Effective multi-hot encoding and classifier for lightweight scene text recognition with a large character set", "title_link": "https://www.researchgate.net/profile/Chun-Guang-Li-2/publication/358098099_Effective_Multi-Hot_Encoding_and_Classifier_for_Lightweight_Scene_Text_Recognition_with_a_Large_Character_Set/links/637ee0b22f4bca7fd088052d/Effective-Multi-Hot-Encoding-and-Classifier-for-Lightweight-Scene-Text-Recognition-with-a-Large-Character-Set.pdf", "id": "QuzVQeVK4p4J", "cited_by_count": 2}, {"title": "[BUCH][B] Tapered-Precision Numerical Formats for Deep Learning Inference and Training", "title_link": "https://search.proquest.com/openview/a88513887d40ec2e6744025447d7d948/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "BKaDncYIgGMJ", "cited_by_count": 0}, {"title": "Mixed-TD: Efficient Neural Network Accelerator with Layer-Specific Tensor Decomposition", "title_link": "https://ieeexplore.ieee.org/abstract/document/10296400/", "id": "Sz5pnkm1DbQJ", "cited_by_count": 0}, {"title": "A methodological framework for optimizing the energy consumption of deep neural networks: a case study of a cyber threat detector", "title_link": "https://link.springer.com/article/10.1007/s00521-024-09588-z", "id": "YI7d-_Hm0gQJ", "cited_by_count": 1}, {"title": "Relu strikes back: Exploiting activation sparsity in large language models", "title_link": "https://arxiv.org/abs/2310.04564", "id": "2sM30rDNoU0J", "cited_by_count": 41}, {"title": "[BUCH][B] Hardware-Aware Efficient Deep Learning", "title_link": "https://search.proquest.com/openview/2b862ba3e326d5c53a77ec5e67adf2b4/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "2pRDLSVvIoUJ", "cited_by_count": 1}, {"title": "Lowering PyTorch's Memory Consumption for Selective Differentiation", "title_link": "https://arxiv.org/abs/2404.12406", "id": "Ns-JZroNhAcJ", "cited_by_count": 0}, {"title": "State of the Art of Machine Learning", "title_link": "https://link.springer.com/chapter/10.1007/978-3-031-46990-9_7", "id": "bMGFNKf4uTIJ", "cited_by_count": 0}, {"title": "Approximate Fault-Tolerant Neural Network Systems", "title_link": "https://ieeexplore.ieee.org/abstract/document/10567290/", "id": "gG8sbseFkoEJ", "cited_by_count": 0}, {"title": "Identification of heart arrhythmias by utilizing a deep learning approach of the ECG signals on edge devices", "title_link": "https://www.mdpi.com/2073-431X/11/12/176", "id": "xeea0y8HatsJ", "cited_by_count": 6}, {"title": "[HTML][HTML] Reinforcement learning-based computation offloading in edge computing: Principles, methods, challenges", "title_link": "https://www.sciencedirect.com/science/article/pii/S1110016824007798", "id": "xNpJR97cnBQJ", "cited_by_count": 0}, {"title": "HW-GPT-Bench: Hardware-Aware Architecture Benchmark for Language Models", "title_link": "https://arxiv.org/abs/2405.10299", "id": "PdIEInYRx6wJ", "cited_by_count": 2}, {"title": "A Review on the emerging technology of TinyML", "title_link": "https://dl.acm.org/doi/abs/10.1145/3661820", "id": "qU2RBl_lnDUJ", "cited_by_count": 2}, {"title": "[BUCH][B] Efficient Hardware Implementation of Deep Learning Networks Based on the Convolutional Neural Network", "title_link": "https://search.proquest.com/openview/88f7fb34f45dd4ff487a123855233d7b/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "3R-XnYuZriAJ", "cited_by_count": 0}, {"title": "Efficient neural networks for tiny machine learning: A comprehensive review", "title_link": "https://arxiv.org/abs/2311.11883", "id": "6lnLfZS4cNAJ", "cited_by_count": 8}, {"title": "[PDF][PDF] In-network ML-based Anomaly Detection", "title_link": "https://davidpissarra.com/thesis.pdf", "id": "OmEk1yAnQekJ", "cited_by_count": 0}, {"title": "[PDF][PDF] Benchmarking public large language model", "title_link": "https://opus4.kobv.de/opus4-haw/files/4593/I001854150Thesis.pdf", "id": "AzH0O1IK4pEJ", "cited_by_count": 20}, {"title": "Enabling Large-Scale Privacy-Preserving Recurrent Neural Networks with Fully Homomorphic Encryption", "title_link": "https://search.proquest.com/openview/9eda6083ce3041bf81a50e4859d57a5e/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "vrjNrnHS4XAJ", "cited_by_count": 0}, {"title": "Evaluation of strategies for the adaptation of large neural models to the task of machine translation in constrained scenarios", "title_link": "https://riunet.upv.es/handle/10251/198517", "id": "ODnomcBEpXcJ", "cited_by_count": 0}, {"title": "Binarized Diffusion Model for Image Super-Resolution", "title_link": "https://arxiv.org/abs/2406.05723", "id": "v6aaO0uUV_oJ", "cited_by_count": 0}, {"title": "Composable interventions for language models", "title_link": "https://arxiv.org/abs/2407.06483", "id": "iLN9v4IQgykJ", "cited_by_count": 2}, {"title": "ExCP: Extreme LLM Checkpoint Compression via Weight-Momentum Joint Shrinking", "title_link": "https://arxiv.org/abs/2406.11257", "id": "8k3WOTzwlUcJ", "cited_by_count": 0}, {"title": "[HTML][HTML] Autocorrelation Matrix Knowledge Distillation: A Task-Specific Distillation Method for BERT Models", "title_link": "https://www.mdpi.com/2076-3417/14/20/9180", "id": "oCivobVYbooJ", "cited_by_count": 0}, {"title": "Deltazip: Multi-tenant language model serving via delta compression", "title_link": "https://arxiv.org/abs/2312.05215", "id": "Qza0g6lGJFwJ", "cited_by_count": 9}, {"title": "LLaMa-SciQ: An Educational Chatbot for Answering Science MCQ", "title_link": "https://arxiv.org/abs/2409.16779", "id": "GH2ol57x2d8J", "cited_by_count": 0}, {"title": "Design automation for fast, lightweight, and effective deep learning models: A survey", "title_link": "https://arxiv.org/abs/2208.10498", "id": "IfReUUxZVDMJ", "cited_by_count": 3}, {"title": "CST: Calibration Side-Tuning for Parameter and Memory Efficient Transfer Learning", "title_link": "https://arxiv.org/abs/2402.12736", "id": "TjzcxOcb440J", "cited_by_count": 0}, {"title": "Approximate Computing and In-Memory Computing: The Best of the Two Worlds!", "title_link": "https://search.proquest.com/openview/3be5d44c649e4c25afb829812c3a56b9/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "HypDB7-4M0YJ", "cited_by_count": 0}, {"title": "[BUCH][B] Compressed Training for Uncertainty-Aware Compact Neural Networks", "title_link": "https://search.proquest.com/openview/a8695767d4b6dc7d7429c3ab2eb7866e/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "OwxnOmaZ34wJ", "cited_by_count": 0}, {"title": "MSD: Mixing Signed Digit Representations for Hardware-efficient DNN Acceleration on FPGA with Heterogeneous Resources", "title_link": "https://ieeexplore.ieee.org/abstract/document/10171562/", "id": "Fpzb2lZOY6AJ", "cited_by_count": 5}, {"title": "A survey on lora of large language models", "title_link": "https://arxiv.org/abs/2407.11046", "id": "k4B--BPLRFwJ", "cited_by_count": 5}, {"title": "Architecting High Performance Silicon Systems for Accurate and Efficient On-Chip Deep Learning", "title_link": "https://search.proquest.com/openview/19ab6db3db1a1658316f5eb66aa4bc51/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "gLv2PW04PXQJ", "cited_by_count": 1}, {"title": "SM2: Towards Similarity-Guided Model Sharding and Merging for Distributed Video Analytics", "title_link": "https://search.proquest.com/openview/e61a81c539faee4affd38c25e32480bf/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "jNUj0mU9nkMJ", "cited_by_count": 0}, {"title": "The Garden of Forking Paths: Observing Dynamic Parameters Distribution in Large Language Models", "title_link": "https://arxiv.org/abs/2403.08739", "id": "rEslO_DsbEsJ", "cited_by_count": 0}, {"title": "[PDF][PDF] Streamlining TinyML Lifecycle with Large Language Models: A Framework for Automation", "title_link": "https://helda.helsinki.fi/bitstreams/d5538b30-169b-4561-a6e8-31d41052d049/download", "id": "lSDC_DUKhZAJ", "cited_by_count": 0}, {"title": "A Scalable, Interpretable, Verifiable & Differentiable Logic Gate Convolutional Neural Network Architecture From Truth Tables", "title_link": "https://arxiv.org/abs/2208.08609", "id": "h4JKNWjggSgJ", "cited_by_count": 0}, {"title": "Multiple Disease Detection using Machine Learning Techniques.", "title_link": "https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=26268493&AN=172014673&h=dd82NBfNXrJxJYz6agZW5RytIL8ya%2FvVlG60horcMS6veX9MswvzE0li2%2BVj0H0cEMttPeRVOSzdXMIRoyz%2FqA%3D%3D&crl=c", "id": "deHgtLwfqz0J", "cited_by_count": 1}, {"title": "Adaptive Mixed-Precision Networks", "title_link": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4274178", "id": "61uuV-Pv6YwJ", "cited_by_count": 0}, {"title": "Minimum variance unbiased n: M sparsity for the neural gradients", "title_link": "https://openreview.net/forum?id=vuD2xEtxZcj", "id": "4AAmp9SG0c0J", "cited_by_count": 5}, {"title": "Accelerating deep neural networks via semi-structured activation sparsity", "title_link": "https://openaccess.thecvf.com/content/ICCV2023W/RCV/html/Grimaldi_Accelerating_Deep_Neural_Networks_via_Semi-Structured_Activation_Sparsity_ICCVW_2023_paper.html", "id": "FWaTFIhsZ_AJ", "cited_by_count": 5}, {"title": "[BUCH][B] Quantization for High-dimensional Data and Neural Networks: Theory and Algorithms", "title_link": "https://search.proquest.com/openview/f2f3b3aa2341a9227a2b1bab77b1cb91/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "K7uHRYgF7LMJ", "cited_by_count": 1}, {"title": "[BUCH][B] Learned Approximate Computing for Machine Learning", "title_link": "https://search.proquest.com/openview/98a47be3c04fde1b385fe67b0547ea46/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "vTABYZKuOfYJ", "cited_by_count": 0}, {"title": "An 8-bit single perceptron processing unit for tiny machine learning applications", "title_link": "https://ieeexplore.ieee.org/abstract/document/10295439/", "id": "vQ3bAy7qK5oJ", "cited_by_count": 8}, {"title": "Algorithms and Frameworks for Generating Neural Network Models Addressing Energy-Efficiency, Robustness, and Privacy", "title_link": "https://search.proquest.com/openview/1d684fba4cb114b9ab512ebb71adef58/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "tBASfFccUUkJ", "cited_by_count": 0}, {"title": "Boolean Variation and Boolean Logic BackPropagation", "title_link": "https://arxiv.org/abs/2311.07427", "id": "slz6vpmg0ksJ", "cited_by_count": 2}, {"title": "Llm-based edge intelligence: A comprehensive survey on architectures, applications, security and trustworthiness", "title_link": "https://ieeexplore.ieee.org/abstract/document/10669603/", "id": "-RnOV_eFq5YJ", "cited_by_count": 3}, {"title": "T3DNet: Compressing Point Cloud Models for Lightweight 3D Recognition", "title_link": "https://arxiv.org/abs/2402.19264", "id": "YI1LylYDnC4J", "cited_by_count": 0}, {"title": "Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications", "title_link": "https://arxiv.org/abs/2408.04680", "id": "M7IdzhIMpE0J", "cited_by_count": 2}, {"title": "An Optimized Hardware Inference of SABiNN: Shift-Accumulate Binarized Neural Network for Sleep Apnea Detection", "title_link": "https://ieeexplore.ieee.org/abstract/document/10136211/", "id": "1wz3Iz47jd8J", "cited_by_count": 3}, {"title": "Embedded Neural Networks in Resource-Constrained Hearing Instruments", "title_link": "https://orbit.dtu.dk/en/publications/embedded-neural-networks-in-resource-constrained-hearing-instrume", "id": "Q3vsiQwMDv0J", "cited_by_count": 0}, {"title": "Training Binary Neural Networks in a Binary Weight Space", "title_link": "https://openreview.net/forum?id=Dm4qrBuFKH", "id": "L4dHzMXAnSgJ", "cited_by_count": 0}, {"title": "Lightweight pixel difference networks for efficient visual representation learning", "title_link": "https://ieeexplore.ieee.org/abstract/document/10198340/", "id": "kmCaZHwDbcYJ", "cited_by_count": 14}, {"title": "zkLLM: Zero Knowledge Proofs for Large Language Models", "title_link": "https://arxiv.org/abs/2404.16109", "id": "rbDw3N-H7BoJ", "cited_by_count": 6}, {"title": "Self-knowledge distillation enhanced binary neural networks derived from underutilized information", "title_link": "https://link.springer.com/article/10.1007/s10489-024-05444-8", "id": "68OWxaE_TQ0J", "cited_by_count": 0}, {"title": "Hardware-Software Co-Design of Deep Neural Networks: From Handcrafted to Automated Design and Deployment", "title_link": "https://mediatum.ub.tum.de/1656745", "id": "vB2yKRuZvXkJ", "cited_by_count": 0}, {"title": "Arithmetic for Deep Learning", "title_link": "https://link.springer.com/chapter/10.1007/978-3-031-42808-1_24", "id": "0RNYdn6Qt2QJ", "cited_by_count": 0}, {"title": "Neural inference at the frontier of energy, space, and time", "title_link": "https://www.science.org/doi/abs/10.1126/science.adh1174", "id": "pW1OlVeWCcEJ", "cited_by_count": 47}, {"title": "Superbnn: Randomized binary neural network using adiabatic superconductor josephson devices", "title_link": "https://dl.acm.org/doi/abs/10.1145/3613424.3623771", "id": "Zj1WrXQbDTQJ", "cited_by_count": 1}, {"title": "Green edge AI: A contemporary survey", "title_link": "https://ieeexplore.ieee.org/abstract/document/10637271/", "id": "hY3VgyrYOokJ", "cited_by_count": 7}, {"title": "Slice-Level Scheduling for High Throughput and Load Balanced LLM Serving", "title_link": "https://arxiv.org/abs/2406.13511", "id": "iZLBB3bCSNwJ", "cited_by_count": 1}, {"title": "Photonic-Electronic Integrated Circuits for High-Performance Computing and AI Accelerators", "title_link": "https://ieeexplore.ieee.org/abstract/document/10598302/", "id": "2nuTkKQebyEJ", "cited_by_count": 2}, {"title": "Deployment of Artificial Intelligence Models on Edge Devices: A Tutorial Brief", "title_link": "https://ieeexplore.ieee.org/abstract/document/10328759/", "id": "sLjXiTKlQs8J", "cited_by_count": 9}, {"title": "Learning verifiable representations", "title_link": "https://research-explorer.ista.ac.at/record/11362", "id": "Y08vhSmhnA0J", "cited_by_count": 0}, {"title": "SiDA: Sparsity-Inspired Data-Aware Serving for Efficient and Scalable Large Mixture-of-Experts Models", "title_link": "https://proceedings.mlsys.org/paper_files/paper/2024/hash/698cfaf72a208aef2e78bcac55b74328-Abstract-Conference.html", "id": "gAKEIunMGvkJ", "cited_by_count": 3}, {"title": "Optimizing DNN Inference on Multi-Accelerator SoCs at Training-time", "title_link": "https://arxiv.org/abs/2409.18566", "id": "h8TBDobPGlYJ", "cited_by_count": 0}, {"title": "LLMServingSim: A HW/SW Co-Simulation Infrastructure for LLM Inference Serving at Scale", "title_link": "https://arxiv.org/abs/2408.05499", "id": "gZlkP1tk6IEJ", "cited_by_count": 1}, {"title": "Systems and Algorithms for Efficient, Secure and Private Machine Learning Inference", "title_link": "https://search.proquest.com/openview/59d7316ee4a5765ce16c455e34a813f6/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "kCpt1j3cqdgJ", "cited_by_count": 0}, {"title": "Low-Cost Language Models: Survey and Performance Evaluation on Python Code Generation", "title_link": "https://arxiv.org/abs/2404.11160", "id": "s2J_xGEXdJEJ", "cited_by_count": 1}, {"title": "NAS-BNN: Neural Architecture Search for Binary Neural Networks", "title_link": "https://arxiv.org/abs/2408.15484", "id": "2Xwf5g9_OAEJ", "cited_by_count": 0}, {"title": "FPGA acceleration of automated ship detection and CNN-based sip/iceberg discriminator in SAR imagery", "title_link": "https://summit.sfu.ca/item/36202", "id": "L3m1Sk7DjJgJ", "cited_by_count": 0}, {"title": "DaCapo: Accelerating Continuous Learning in Autonomous Systems for Video Analytics", "title_link": "https://arxiv.org/abs/2403.14353", "id": "CYREJWhH5VkJ", "cited_by_count": 2}, {"title": "[PDF][PDF] Mapping Efficient Convolutional Neural Networks to Resource-Limited System-on-Chip Field-Programmable Gate Arrays for Mobile Deep Learning Application\u00a0\u2026", "title_link": "https://ikee.lib.auth.gr/record/354668/files/GRI-2024-43162.pdf", "id": "1KD003nslWwJ", "cited_by_count": 0}, {"title": "Approximations in deep learning", "title_link": "https://link.springer.com/chapter/10.1007/978-3-030-94705-7_15", "id": "bdmgHEhInRUJ", "cited_by_count": 6}, {"title": "Efficient and effective text encoding for chinese llama and alpaca", "title_link": "https://arxiv.org/abs/2304.08177", "id": "MvhRbsqnhGgJ", "cited_by_count": 214}, {"title": "GOENet: Group Operations Enhanced Binary Neural Network for Efficient Image Classification", "title_link": "https://ieeexplore.ieee.org/abstract/document/10487018/", "id": "iP9KZJIVFiUJ", "cited_by_count": 0}, {"title": "Scgnet: Shifting and cascaded group network", "title_link": "https://ieeexplore.ieee.org/abstract/document/10049473/", "id": "PRq7GpdLndYJ", "cited_by_count": 8}, {"title": "Boolean Logic for Low-Energy Deep Learning", "title_link": "https://openreview.net/forum?id=YyVJctb2v4", "id": "BKJ4EUM6P34J", "cited_by_count": 0}, {"title": "[BUCH][B] Applying Deep Compression to Enable Spoken Language Edge Inference", "title_link": "https://search.proquest.com/openview/61f095f4db462b9a1cde6ff7b1d266de/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "cH7ucZ4F2ukJ", "cited_by_count": 0}, {"title": "[HTML][HTML] Deep neural networks compression: A comparative survey and choice recommendations", "title_link": "https://www.sciencedirect.com/science/article/pii/S0925231222014643", "id": "-7ukhpAauHgJ", "cited_by_count": 59}, {"title": "Deployment of Artificial Intelligence Models into Edge Devices: A Tutorial Brief", "title_link": "https://www.techrxiv.org/doi/full/10.36227/techrxiv.24072675.v1", "id": "7PolkyHnOxAJ", "cited_by_count": 0}, {"title": "A tutorial on open-source large language models for behavioral science", "title_link": "https://link.springer.com/article/10.3758/s13428-024-02455-8", "id": "G0yByGfqwU8J", "cited_by_count": 17}, {"title": "Training with Mixed-Precision Floating-Point Assignments", "title_link": "https://arxiv.org/abs/2301.13464", "id": "uPAAE9UaYvcJ", "cited_by_count": 2}, {"title": "Point cloud based semantic segmentation for catenary systems using deep learning: Compressibility of a PointNet++ network", "title_link": "http://essay.utwente.nl/92901/", "id": "nQx0Vr6qTlQJ", "cited_by_count": 1}, {"title": "Towards Efficient Edge Intelligence with In-Sensor and Neuromorphic Computing: Algorithm-Hardware Co-Design", "title_link": "https://search.proquest.com/openview/e79564c23f94637851dc65eb792decec/1?pq-origsite=gscholar&cbl=18750&diss=y", "id": "PMKzo3ZsnhsJ", "cited_by_count": 0}, {"title": "CaM: Cache Merging for Memory-efficient LLMs Inference", "title_link": "https://openreview.net/forum?id=LCTmppB165", "id": "LAedpErOmMUJ", "cited_by_count": 0}, {"title": "Amphista: Accelerate LLM Inference with Bi-directional Multiple Drafting Heads in a Non-autoregressive Style", "title_link": "https://arxiv.org/abs/2406.13170", "id": "xWcavRF_HX0J", "cited_by_count": 3}, {"title": "Structured binary neural networks for image recognition", "title_link": "https://link.springer.com/article/10.1007/s11263-022-01638-0", "id": "ARmuOep3jWsJ", "cited_by_count": 23}, {"title": "[PDF][PDF] DACAPO: Accelerating Continuous Learning in Autonomous Systems for Video Analytics", "title_link": "https://jongse-park.github.io/files/paper/2024-isca-dacapo.pdf", "id": "AxLgURgU-fwJ", "cited_by_count": 0}, {"title": "End-to-End Neural Network Compression via  Regularized Latency Surrogates", "title_link": "https://arxiv.org/abs/2306.05785", "id": "xjYvuSMlufIJ", "cited_by_count": 0}, {"title": "Compiler-centric across-stack deep learning acceleration", "title_link": "https://theses.gla.ac.uk/83959/", "id": "7DWvWuzNqdYJ", "cited_by_count": 1}]]