{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Google Scholar Entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote_plus\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transformer+AND+%28%222-bit%22+OR+%222bit%22+OR+%222+bit%22+OR+%221-bit%22+OR+%221bit%22+OR+%221+bit%22%29+AND+%28%22post-training%22+OR+%22post+training%22%29+AND+%22quantization%22+AND+%22function%22+-%22image+compression%22'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEBUG = False\n",
    "#RAW_SEARCH_STRING = '(transformer OR llm) AND (extreme OR low bit OR 8-bit OR 4-bit OR 2-bit OR 1-bit) AND \"quantization function\"'\n",
    "RAW_SEARCH_STRING = 'transformer AND (\"2-bit\" OR \"2bit\" OR \"2 bit\" OR \"1-bit\" OR \"1bit\" OR \"1 bit\") AND (\"post-training\" OR \"post training\") AND \"quantization\" AND \"function\" -\"image compression\"'\n",
    "SEARCH_STRING = quote_plus(RAW_SEARCH_STRING)\n",
    "FROM_YEAR = \"as_ylo=2022\"\n",
    "SEARCH_STRING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning:\n",
      "\n",
      "Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "\n",
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning:\n",
      "\n",
      "Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">\n",
       "\n",
       "<html dir=\"LTR\">\n",
       "<head><meta content=\"text/html; charset=utf-8\" http-equiv=\"content-type\"/><meta content=\"initial-scale=1\" name=\"viewport\"/><title>https://www.google.com/scholar?q=transformer+AND+%28%222-bit%22+OR+%222bit%22+OR+%222+bit%22+OR+%221-bit%22+OR+%221bit%22+OR+%221+bit%22%29+AND+%28%22post-training%22+OR+%22post+training%22%29+AND+%22quantization%22+AND+%22function%22+-%22image+compression%22&amp;hl=de&amp;as_ylo=2022</title></head>\n",
       "<body onload=\"e=document.getElementById('captcha');if(e){e.focus();} if(solveSimpleChallenge) {solveSimpleChallenge(,);}\" style=\"font-family: arial, sans-serif; background-color: #fff; color: #000; padding:20px; font-size:18px; overscroll-behavior:contain;\">\n",
       "<div style=\"max-width:400px;\">\n",
       "<hr noshade=\"\" size=\"1\" style=\"color:#ccc; background-color:#ccc;\"/><br/>\n",
       "<form action=\"index\" id=\"captcha-form\" method=\"post\">\n",
       "<noscript>\n",
       "<div style=\"font-size:13px;\">\n",
       "Um fortzufahren, musst du JavaScript in deinem Browser aktivieren.\n",
       "</div>\n",
       "</noscript>\n",
       "<script async=\"\" defer=\"\" src=\"https://www.google.com/recaptcha/api.js\"></script>\n",
       "<script>var submitCallback = function(response) {document.getElementById('captcha-form').submit();};</script>\n",
       "<div class=\"g-recaptcha\" data-callback=\"submitCallback\" data-s=\"tQtCxMziScX11nP5aymAJbTPY3UMgTQDchbBdujGMB2uQvAQzK9kSLLAHgKYBxtPfkQkFCKP8jUszp9Pwf01pSTItujHX63zniIMxKEmZ-zf3MMKzcpUCKbPDCBzJzRJZ8Kr4eDpS2OwJBNNlKNkCo8aoujLvR6ulhFhlvlOPXewxLyWbjcDnLEQMjXW2hkmc-r3pU_9J-ZrCngb5TNpg9SGr5yu38EFvpt63vpxSvZDFy8kK1W13Psd3F_MtLP65iu5vGT8CKY_s-VTFOFLkQN2\" data-sitekey=\"6LfwuyUTAAAAAOAmoS0fdqijC2PbbdH4kjq62Y1b\" id=\"recaptcha\"></div>\n",
       "<input name=\"q\" type=\"hidden\" value=\"EgSToar_GN3H3rgGIizQz_V-bx1m48CsS0OhzHnWG45Ob5nrseDrDTAm8VB3Vk0AM9RL0t7HjaPLlzIBcloBQw\"/><input name=\"continue\" type=\"hidden\" value=\"https://www.google.com/scholar?q=transformer+AND+%28%222-bit%22+OR+%222bit%22+OR+%222+bit%22+OR+%221-bit%22+OR+%221bit%22+OR+%221+bit%22%29+AND+%28%22post-training%22+OR+%22post+training%22%29+AND+%22quantization%22+AND+%22function%22+-%22image+compression%22&amp;hl=de&amp;as_ylo=2022\"/>\n",
       "</form>\n",
       "<hr noshade=\"\" size=\"1\" style=\"color:#ccc; background-color:#ccc;\"/>\n",
       "<div style=\"font-size:13px;\">\n",
       "<b>Ãber diese Seite</b><br/><br/>\n",
       "\n",
       "Unsere Systeme haben ungewÃ¶hnlichen Datenverkehr aus Ihrem Computernetzwerk festgestellt. Diese Seite Ã¼berprÃ¼ft, ob die Anfragen wirklich von Ihnen und nicht von einem Robot gesendet werden. <a href=\"#\" onclick=\"document.getElementById('infoDiv').style.display='block';\">Warum?</a><br/><br/>\n",
       "<div id=\"infoDiv\" style=\"display:none; background-color:#eee; padding:10px; margin:0 0 15px 0; line-height:1.4em;\">\n",
       "Diese Seite wird angezeigt, wenn Google automatisch Anfragen aus Ihrem Computernetzwerk erkennt, die anscheinend gegen die <a href=\"//www.google.com/policies/terms/\">Nutzungsbedingungen</a> verstoÃen. Die Sperre lÃ¤uft ab, sobald diese Anfragen eingestellt werden. In der Zwischenzeit kÃ¶nnen Sie unsere Dienste weiterhin mithilfe des oben stehenden CAPTCHAs nutzen.<br/><br/>Dieser Datenverkehr wurde mÃ¶glicherweise von bÃ¶sartiger Software, einem Browser-Plug-in oder einem Skript gesendet, das automatische Anfragen verschickt. Falls Sie Ihre Netzwerkverbindung mit anderen teilen, bitten Sie Ihren Administrator um Hilfe. MÃ¶glicherweise ist ein anderer Computer, der dieselbe IP-Adresse verwendet, fÃ¼r die Anfragen verantwortlich. <a href=\"//support.google.com/websearch/answer/86640\">Weitere Informationen</a><br/><br/>Eventuell werden Sie um Eingabe des CAPTCHAs gebeten, weil Sie komplexe Anfragen verwenden, die bekanntermaÃen von Robots verwendet werden, oder weil Sie sehr schnell Anfragen senden.\n",
       "\n",
       "</div><br/>\n",
       "IP-Adresse: 147.161.170.255<br/>Uhrzeit: 2024-10-22T13:08:46Z<br/>URL: https://www.google.com/scholar?q=transformer+AND+%28%222-bit%22+OR+%222bit%22+OR+%222+bit%22+OR+%221-bit%22+OR+%221bit%22+OR+%221+bit%22%29+AND+%28%22post-training%22+OR+%22post+training%22%29+AND+%22quantization%22+AND+%22function%22+-%22image+compression%22&amp;hl=de&amp;as_ylo=2022<br/>\n",
       "</div></div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f\"https://www.google.com/scholar?q={SEARCH_STRING}&hl=de&{FROM_YEAR}\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.361681261652\"\n",
    "}\n",
    "response = requests.get(url, headers=headers, verify=False)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Function definition for downloading and iterating through scholar pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadScholarDataPage(start_from: int = 0):\n",
    "    try:\n",
    "        url = f\"https://www.google.com/scholar?start={start_from}&q={SEARCH_STRING}&hl=de&{FROM_YEAR}\"\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.361681261652\"\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, verify=False)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        print(\"Download from URL:\", url)\n",
    "        try:\n",
    "            total_hits = soup.select(\".gs_ab_mdw\")[-1].text.split(\" \")[-4] #example how this string looks: Seite 17 von ungefähr 1.692 Ergebnissen (0,05 Sek.)\n",
    "            \n",
    "        except Exception as e: \n",
    "            print(\"Couldn't retrieve number of results. Due to error:\", e)\n",
    "            total_hits = None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Couldn't retrieve website due to error:\", e)\n",
    "    return total_hits, soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScholarData(soup: BeautifulSoup):\n",
    "    scholar_results = []\n",
    "    items_skipped = 0\n",
    "\n",
    "    for el in soup.select(\".gs_scl\"):\n",
    "        try:\n",
    "            if DEBUG:\n",
    "                print(\"title:\", el.select(\".gs_rt\")[0].text)\n",
    "                print(\"title_link:\", el.select(\".gs_rt a\")[0][\"href\"])\n",
    "                print(\"id:\", el.select(\".gs_rt a\")[0][\"id\"])\n",
    "                print(\"cited_by_count:\", el.select(\".gs_nph+ a\")[0].text.split(\"Zitiert von: \")[-1])\n",
    "\n",
    "            cite_count = el.select(\".gs_nph+ a\")[0].text\n",
    "            if \"ähnliche artikel\" in cite_count.lower():\n",
    "                cite_count = 0\n",
    "            elif \"zitiert von\" in cite_count.lower():\n",
    "                cite_count = int(cite_count.split(\"Zitiert von: \")[-1])\n",
    "\n",
    "            scholar_results.append({\n",
    "                \"title\": el.select(\".gs_rt\")[0].text,\n",
    "                \"title_link\": el.select(\".gs_rt a\")[0][\"href\"],\n",
    "                \"id\": el.select(\".gs_rt a\")[0][\"id\"],\n",
    "                #\"displayed_link\": el.select(\".gs_a\")[0].text,\n",
    "                #\"snippet\": el.select(\".gs_rs\")[0].text.replace(\"\\n\", \"\"),\n",
    "                \"cited_by_count\": cite_count,\n",
    "                #\"cited_link\": \"https://scholar.google.com\" + el.select(\".gs_nph+ a\")[0][\"href\"],\n",
    "                #\"versions_count\": el.select(\"a~ a+ .gs_nph\")[0].text,\n",
    "                #\"versions_link\": \"https://scholar.google.com\" + el.select(\"a~ a+ .gs_nph\")[0][\"href\"] if el.select(\"a~ a+ .gs_nph\")[0].text else \"\",\n",
    "            })\n",
    "        except Exception as e:\n",
    "            items_skipped += 1\n",
    "            print(\"Couldn't append item. Due to error: \", e)\n",
    "    for i in range(len(scholar_results)):\n",
    "        scholar_results[i] = {key: value for key, value in scholar_results[i].items() if value != \"\" and value is not None}\n",
    "\n",
    "    print(scholar_results)\n",
    "    return items_skipped, scholar_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterateScholarPages(start: int = 0):\n",
    "    start_from = start\n",
    "    total_items_skipped = 0\n",
    "    total_results = []\n",
    "    try:\n",
    "        max_item, soup = downloadScholarDataPage(start_from)\n",
    "        print(\"Max items:\", max_item)\n",
    "        items_skipped, scholar_results = getScholarData(soup)\n",
    "        if scholar_results is []:\n",
    "            print(\"Too many requests were sent and google sends no proper results\")\n",
    "            print(f\"Arived at '0' results out of approximately '0' max results\")\n",
    "            return total_items_skipped, total_results\n",
    "\n",
    "        total_items_skipped += items_skipped\n",
    "        total_results.extend(scholar_results)\n",
    "        \n",
    "        # remove all \".\" from the number and turn it into an integer\n",
    "        max_item = int(\"\".join(max_item.split(\".\"))) \n",
    "        while start_from < max_item:\n",
    "            print(f\"Currently at '{start_from+1}' out of '{max_item}' results\")\n",
    "            random_sleep = random.random()*1.5\n",
    "            time.sleep(random_sleep)\n",
    "            \n",
    "        \n",
    "            start_from += 10\n",
    "            _, soup = downloadScholarDataPage(start_from)\n",
    "\n",
    "            items_skipped, scholar_results = getScholarData(soup)\n",
    "            if scholar_results is []:\n",
    "                print(\"Too many requests were sent and google sends no proper results\")\n",
    "                print(f\"Arived at '{start_from-9}' results out of approximately '{max_item}' max results\")\n",
    "                return total_items_skipped, total_results\n",
    "                \n",
    "            total_items_skipped += items_skipped\n",
    "            total_results.extend(scholar_results)\n",
    "\n",
    "        return total_items_skipped, total_results\n",
    "    \n",
    "    except Exception as e:\n",
    "        if e == KeyboardInterrupt:\n",
    "            return total_items_skipped, total_results\n",
    "        else:\n",
    "            print(\"Error occured:\", e)\n",
    "            return total_items_skipped, total_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'scholar.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download from URL: https://www.google.com/scholar?start=631&q=transformer+AND+%28%222-bit%22+OR+%222bit%22+OR+%222+bit%22+OR+%221-bit%22+OR+%221bit%22+OR+%221+bit%22%29+AND+%28%22post-training%22+OR+%22post+training%22%29+AND+%22quantization%22+AND+%22function%22+-%22image+compression%22&hl=de&as_ylo=2022\n",
      "Max items: 688\n",
      "Couldn't append item. Due to error:  list index out of range\n",
      "[{'title': 'Training with Mixed-Precision Floating-Point Assignments', 'title_link': 'https://arxiv.org/abs/2301.13464', 'id': 'uPAAE9UaYvcJ', 'cited_by_count': 2}, {'title': 'Point cloud based semantic segmentation for catenary systems using deep learning: Compressibility of a PointNet++ network', 'title_link': 'http://essay.utwente.nl/92901/', 'id': 'nQx0Vr6qTlQJ', 'cited_by_count': 1}, {'title': 'Towards Efficient Edge Intelligence with In-Sensor and Neuromorphic Computing: Algorithm-Hardware Co-Design', 'title_link': 'https://search.proquest.com/openview/e79564c23f94637851dc65eb792decec/1?pq-origsite=gscholar&cbl=18750&diss=y', 'id': 'PMKzo3ZsnhsJ', 'cited_by_count': 0}, {'title': 'CaM: Cache Merging for Memory-efficient LLMs Inference', 'title_link': 'https://openreview.net/forum?id=LCTmppB165', 'id': 'LAedpErOmMUJ', 'cited_by_count': 0}, {'title': 'Amphista: Accelerate LLM Inference with Bi-directional Multiple Drafting Heads in a Non-autoregressive Style', 'title_link': 'https://arxiv.org/abs/2406.13170', 'id': 'xWcavRF_HX0J', 'cited_by_count': 3}, {'title': 'Structured binary neural networks for image recognition', 'title_link': 'https://link.springer.com/article/10.1007/s11263-022-01638-0', 'id': 'ARmuOep3jWsJ', 'cited_by_count': 23}, {'title': '[PDF][PDF] DACAPO: Accelerating Continuous Learning in Autonomous Systems for Video Analytics', 'title_link': 'https://jongse-park.github.io/files/paper/2024-isca-dacapo.pdf', 'id': 'AxLgURgU-fwJ', 'cited_by_count': 0}, {'title': 'End-to-End Neural Network Compression via  Regularized Latency Surrogates', 'title_link': 'https://arxiv.org/abs/2306.05785', 'id': 'xjYvuSMlufIJ', 'cited_by_count': 0}, {'title': 'Compiler-centric across-stack deep learning acceleration', 'title_link': 'https://theses.gla.ac.uk/83959/', 'id': '7DWvWuzNqdYJ', 'cited_by_count': 1}, {'title': '[PDF][PDF] NEURAL APPROACHES TO THEOREM SEARCH & PROOF REPAIR', 'title_link': 'https://tompreichel.com/thesis.pdf', 'id': 'LSeVrl9G33oJ', 'cited_by_count': 0}]\n",
      "Currently at '632' out of '688' results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'scholar.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download from URL: https://www.google.com/scholar?start=641&q=transformer+AND+%28%222-bit%22+OR+%222bit%22+OR+%222+bit%22+OR+%221-bit%22+OR+%221bit%22+OR+%221+bit%22%29+AND+%28%22post-training%22+OR+%22post+training%22%29+AND+%22quantization%22+AND+%22function%22+-%22image+compression%22&hl=de&as_ylo=2022\n",
      "Couldn't append item. Due to error:  list index out of range\n",
      "Couldn't append item. Due to error:  list index out of range\n",
      "[{'title': 'CFSP: An Efficient Structured Pruning Framework for LLMs with Coarse-to-Fine Activation Information', 'title_link': 'https://arxiv.org/abs/2409.13199', 'id': 'uaHy3r0GVwEJ', 'cited_by_count': 0}, {'title': '[PDF][PDF] Implementation of Machine Learning Algorithms on Ultra-Low-Power Hardware for In-Sensor Inference', 'title_link': 'https://tesidottorato.depositolegale.it/bitstream/20.500.14242/156910/1/conv_tesi-final.pdf', 'id': 'dMmPaT08ClQJ', 'cited_by_count': 0}, {'title': 'MoE-Pruner: Pruning Mixture-of-Experts Large Language Model using the Hints from Its Router', 'title_link': 'https://arxiv.org/abs/2410.12013', 'id': 'Jvsm4FODeBMJ', 'cited_by_count': 0}, {'title': 'Knowledge-preserving Pruning for Pre-trained Language Models without Retraining', 'title_link': 'https://arxiv.org/abs/2308.03449', 'id': 'AK8FIQjyHxoJ', 'cited_by_count': 2}, {'title': 'Binary Dense Predictors for Human Pose Estimation Based on Dynamic Thresholds and Filtering', 'title_link': 'https://ieeexplore.ieee.org/abstract/document/9746998/', 'id': 'DiyHgJSSpnQJ', 'cited_by_count': 2}, {'title': '[PDF][PDF] Hardware-Software Co-Design for Energy-Efficient Neural Network Inference at the Extreme Edge', 'title_link': 'https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/698281/1/Doctoral_Thesis-5.pdf', 'id': 'qMCjXd6An6AJ', 'cited_by_count': 0}, {'title': 'Smoothing Disruption Across the Stack: Tales of Memory, Heterogeneity, & Compilers', 'title_link': 'https://ieeexplore.ieee.org/abstract/document/10546772/', 'id': '-FTlsI6yDD8J', 'cited_by_count': 0}, {'title': '[BUCH][B] Model Compression for Efficient Machine Learning Inference', 'title_link': 'https://search.proquest.com/openview/fb05ec5a8feb8ad931b6f422904ca14a/1?pq-origsite=gscholar&cbl=18750&diss=y', 'id': '5s2fOyC_X94J', 'cited_by_count': 0}, {'title': 'Near-Memory Processing for Low-precision Deep Neural Networks', 'title_link': 'https://www.repository.cam.ac.uk/items/cf64e959-1ec5-453e-900a-e16f1f5eefc1', 'id': '5pMN3EuODN8J', 'cited_by_count': 0}]\n",
      "Currently at '642' out of '688' results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'scholar.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download from URL: https://www.google.com/scholar?start=651&q=transformer+AND+%28%222-bit%22+OR+%222bit%22+OR+%222+bit%22+OR+%221-bit%22+OR+%221bit%22+OR+%221+bit%22%29+AND+%28%22post-training%22+OR+%22post+training%22%29+AND+%22quantization%22+AND+%22function%22+-%22image+compression%22&hl=de&as_ylo=2022\n",
      "Couldn't append item. Due to error:  list index out of range\n",
      "[{'title': 'Update compression for deep neural networks on the edge', 'title_link': 'https://openaccess.thecvf.com/content/CVPR2022W/MobileAI/html/Chen_Update_Compression_for_Deep_Neural_Networks_on_the_Edge_CVPRW_2022_paper.html', 'id': 'hEaGT1012BYJ', 'cited_by_count': 16}, {'title': '[PDF][PDF] Evaluation of the DL accelerator designs', 'title_link': 'https://vedliot.eu/wp-content/uploads/2024/05/VEDLIoT_Deliverable_D3.3_v1.1_submitted.pdf', 'id': 'kqqREk2VTqYJ', 'cited_by_count': 0}, {'title': 'HadSkip: Homotopic and Adaptive Layer Skipping of Pre-trained Language Models for Efficient Inference', 'title_link': 'https://aclanthology.org/2023.findings-emnlp.283/', 'id': 'gY0EyTHvxdwJ', 'cited_by_count': 2}, {'title': 'Weightless neural networks for fast, low-energy inference', 'title_link': 'https://repositories.lib.utexas.edu/items/724dfac2-7346-4f1a-867b-511848686d80', 'id': '3ruS8Gy8i8oJ', 'cited_by_count': 0}, {'title': '[PDF][PDF] Improving image sensor performance by developing on-chip machine learning algorithms', 'title_link': 'https://www.duo.uio.no/bitstream/handle/10852/106555/1/Thesis.pdf', 'id': 's7f0aD8K7j8J', 'cited_by_count': 0}, {'title': 'Accurate Retraining-free Pruning for Pretrained Encoder-based Language Models', 'title_link': 'https://openreview.net/forum?id=s2NjWfaYdZ', 'id': 'lueEDZs9qDYJ', 'cited_by_count': 2}, {'title': 'Zero redundancy distributed learning with differential privacy', 'title_link': 'https://arxiv.org/abs/2311.11822', 'id': 'tq6QVGexp3IJ', 'cited_by_count': 3}, {'title': 'Inca: Input-stationary dataflow at outside-the-box thinking about deep learning accelerators', 'title_link': 'https://ieeexplore.ieee.org/abstract/document/10070992/', 'id': 'Mq5Os6FmTHAJ', 'cited_by_count': 8}, {'title': 'Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures', 'title_link': 'https://arxiv.org/abs/2405.04700', 'id': 'bpI_3TWycbwJ', 'cited_by_count': 2}, {'title': 'A transistor operations model for deep learning energy consumption scaling law', 'title_link': 'https://ieeexplore.ieee.org/abstract/document/9984954/', 'id': '3EGSLPkGGLcJ', 'cited_by_count': 1}]\n",
      "Currently at '652' out of '688' results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'scholar.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download from URL: https://www.google.com/scholar?start=661&q=transformer+AND+%28%222-bit%22+OR+%222bit%22+OR+%222+bit%22+OR+%221-bit%22+OR+%221bit%22+OR+%221+bit%22%29+AND+%28%22post-training%22+OR+%22post+training%22%29+AND+%22quantization%22+AND+%22function%22+-%22image+compression%22&hl=de&as_ylo=2022\n",
      "Couldn't append item. Due to error:  list index out of range\n",
      "[{'title': 'Boosted dynamic neural networks', 'title_link': 'https://ojs.aaai.org/index.php/AAAI/article/view/26302', 'id': 'mOUt69Abtu0J', 'cited_by_count': 13}, {'title': 'The Evolution of Mixture of Experts: A Survey from Basics to Breakthroughs', 'title_link': 'https://www.preprints.org/manuscript/202408.0583', 'id': 'JHBZ0S25LvsJ', 'cited_by_count': 0}, {'title': 'Investigations into Ultra-Low-Power Underwater Imaging', 'title_link': 'https://dspace.mit.edu/handle/1721.1/152645', 'id': 'AYwujT4-pNgJ', 'cited_by_count': 0}, {'title': 'On-Chip DNN Training for Direct Feedback Alignment in FeFET', 'title_link': 'https://link.springer.com/chapter/10.1007/978-3-031-19568-6_11', 'id': 'zQX1LuHGM5gJ', 'cited_by_count': 0}, {'title': 'Spiking Diffusion Models', 'title_link': 'https://ieeexplore.ieee.org/abstract/document/10665907/', 'id': 'JAeWI-5VIP8J', 'cited_by_count': 0}, {'title': 'Improving the Efficiency and Robustness of In-Memory Computing in Emerging Technologies', 'title_link': 'https://search.proquest.com/openview/3aef46e2dd34370a9ece49bca2ea21d8/1?pq-origsite=gscholar&cbl=18750&diss=y', 'id': '8odoBkUqkbEJ', 'cited_by_count': 0}, {'title': '[PDF][PDF] The Evolution of MoE: A Survey from Basics to Breakthroughs', 'title_link': 'https://www.researchgate.net/profile/Arpita-Vats/publication/382916607_THE_EVOLUTION_OF_MIXTURE_OF_EXPERTS_A_SURVEY_FROM_BASICS_TO_BREAKTHROUGHS/links/66e7627cdde50b3258771e3a/THE-EVOLUTION-OF-MIXTURE-OF-EXPERTS-A-SURVEY-FROM-BASICS-TO-BREAKTHROUGHS.pdf', 'id': 'rN4lcZ5oWSUJ', 'cited_by_count': 0}, {'title': 'Sensitivity-Aware Finetuning for Accuracy Recovery on Deep Learning Hardware', 'title_link': 'https://arxiv.org/abs/2306.03076', 'id': 'YiLyF6uAeasJ', 'cited_by_count': 0}, {'title': 'From decoding to meta-generation: Inference-time algorithms for large language models', 'title_link': 'https://arxiv.org/abs/2406.16838', 'id': 'seevFgZNHtUJ', 'cited_by_count': 2}, {'title': 'Maestro: Uncovering Low-Rank Structures via Trainable Decomposition', 'title_link': 'https://arxiv.org/abs/2308.14929', 'id': 'OQ2JJPWMN3QJ', 'cited_by_count': 2}]\n",
      "Currently at '662' out of '688' results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'scholar.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download from URL: https://www.google.com/scholar?start=671&q=transformer+AND+%28%222-bit%22+OR+%222bit%22+OR+%222+bit%22+OR+%221-bit%22+OR+%221bit%22+OR+%221+bit%22%29+AND+%28%22post-training%22+OR+%22post+training%22%29+AND+%22quantization%22+AND+%22function%22+-%22image+compression%22&hl=de&as_ylo=2022\n",
      "Couldn't append item. Due to error:  list index out of range\n",
      "[{'title': 'High-efficiency Compressor Trees for Latest AMD FPGAs', 'title_link': 'https://dl.acm.org/doi/abs/10.1145/3645097', 'id': 'zOtKKcFor1IJ', 'cited_by_count': 0}, {'title': ': Confidence Calibration Model Cascade for Inference-Efficient Cross-Lingual Natural Language Understanding', 'title_link': 'https://arxiv.org/abs/2402.15991', 'id': 'O3rXMDBh-x0J', 'cited_by_count': 0}, {'title': 'Power-Efficient Machine Learning-Based Hardware Architectures for Biomedical Applications', 'title_link': 'https://search.proquest.com/openview/8f3221666e8cc75be537c6243324852e/1?pq-origsite=gscholar&cbl=18750&diss=y', 'id': 'LQ0qKJbj-MUJ', 'cited_by_count': 0}, {'title': '[PDF][PDF] Natural Language Conditioned Planning of Complex Robotics Tasks', 'title_link': 'https://library.oapen.org/bitstream/handle/20.500.12657/87610/9781040027042.pdf?sequence=1#page=158', 'id': 'SjbLCWDt6MoJ', 'cited_by_count': 0}, {'title': 'Towards Efficient Coarse-grained Dialogue Response Selection', 'title_link': 'https://dl.acm.org/doi/abs/10.1145/3597609', 'id': '0MwYSP8omqoJ', 'cited_by_count': 0}, {'title': 'Training binary neural networks without floating point precision', 'title_link': 'https://arxiv.org/abs/2310.19815', 'id': 'jn82PKKjemMJ', 'cited_by_count': 0}, {'title': '[PDF][PDF] Large Language Models for Creation, Enrichment and Evaluation of Taxonomic Graphs', 'title_link': 'https://semantic-web-journal.net/system/files/swj3751.pdf', 'id': '2iEJXUnG66kJ', 'cited_by_count': 0}, {'title': '[BUCH][B] Holistic Algorithm and System Co-Optimization for Trustworthy and Platform-Aware Deep Learning', 'title_link': 'https://search.proquest.com/openview/e15ae40c8ca147d0864841909e8650d9/1?pq-origsite=gscholar&cbl=18750&diss=y', 'id': 'VoVP8UlNC6UJ', 'cited_by_count': 0}, {'title': 'Practical processing and acceleration of graph neural networks', 'title_link': 'https://www.repository.cam.ac.uk/items/27470a7b-911d-46d4-8920-a6e68ff00016', 'id': 'P3tfHzHGtMYJ', 'cited_by_count': 0}, {'title': 'Low-Latency BERT Inference for heterogeneous multi-processor edge devices', 'title_link': 'https://escholarship.mcgill.ca/concern/theses/gf06g783t', 'id': '1eoPkZ0rAMoJ', 'cited_by_count': 0}]\n",
      "Currently at '672' out of '688' results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'scholar.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download from URL: https://www.google.com/scholar?start=681&q=transformer+AND+%28%222-bit%22+OR+%222bit%22+OR+%222+bit%22+OR+%221-bit%22+OR+%221bit%22+OR+%221+bit%22%29+AND+%28%22post-training%22+OR+%22post+training%22%29+AND+%22quantization%22+AND+%22function%22+-%22image+compression%22&hl=de&as_ylo=2022\n",
      "Couldn't append item. Due to error:  list index out of range\n",
      "[{'title': 'Environment-aware knowledge distillation for improved resource-constrained edge speech recognition.', 'title_link': 'https://espace.inrs.ca/id/eprint/15682/', 'id': '3Vds-2mjXl0J', 'cited_by_count': 0}, {'title': 'Agile and Efficient Inference of Quantized Neural Networks', 'title_link': 'https://www.research-collection.ethz.ch/handle/20.500.11850/675547', 'id': 'rPWn_VOIrp8J', 'cited_by_count': 0}, {'title': '[PDF][PDF] Αριστοτέλειο Πανεπιστή ιο Θεσσαλονίκης', 'title_link': 'https://ikee.lib.auth.gr/record/354668/files/manuscript_18042024.pdf', 'id': 'I2G4NMsdqvQJ', 'cited_by_count': 0}, {'title': '[PDF][PDF] 高效能二值化權重神經網路之設計與實現', 'title_link': 'https://tdr.lib.ntu.edu.tw/retrieve/b57a7ec3-aa70-4e87-aee4-13102ba1c95c/ntu-112-2.pdf', 'id': 'OJWsCPXyK9UJ', 'cited_by_count': 0}, {'title': 'Optimalizace LLM agentů pro analýzu tabulkových dat: Integrace LoRA pro zvýšení kvality', 'title_link': 'https://dspace.cvut.cz/handle/10467/115388', 'id': 'vfiBh4jwSoAJ', 'cited_by_count': 0}, {'title': 'Directly training spiking neural networks for cyber-physical systems: from supervised to reinforcement learning', 'title_link': 'http://amsdottorato.unibo.it/11309/', 'id': 'JN5yzCT3JuwJ', 'cited_by_count': 0}, {'title': 'Enabling Semantic Reasoning in Robots through Natural Language Processing', 'title_link': 'https://ntnuopen.ntnu.no/ntnu-xmlui/handle/11250/3157083', 'id': 'Lp-ZiqrMecUJ', 'cited_by_count': 0}]\n",
      "Currently at '682' out of '688' results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/dominic/miniconda3/envs/scholar/lib/python3.9/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'scholar.google.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download from URL: https://www.google.com/scholar?start=691&q=transformer+AND+%28%222-bit%22+OR+%222bit%22+OR+%222+bit%22+OR+%221-bit%22+OR+%221bit%22+OR+%221+bit%22%29+AND+%28%22post-training%22+OR+%22post+training%22%29+AND+%22quantization%22+AND+%22function%22+-%22image+compression%22&hl=de&as_ylo=2022\n",
      "Couldn't append item. Due to error:  list index out of range\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "res = iterateScholarPages(631)\n",
    "skipped, total_results = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Statistics###\n",
      "Google Results: 64\n",
      "No #citations: 8\n",
      "Papers with citations: 56\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"###Statistics###\n",
    "Google Results: {skipped+ len(total_results)}\n",
    "No #citations: {skipped}\n",
    "Papers with citations: {len(total_results)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Persist or load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from disk\n",
    "def load_from_disk(file_name: str):\n",
    "    #FILE = \"%28transformer+OR+llm%29+AND+%28extreme+OR+low+bit+OR+8-bit+OR+4-bit+OR+2-bit+OR+1-bit%29+AND+%22quantization+function%22__1729496820.4837933\"\n",
    "    with open(file_name, \"r\") as f:\n",
    "        skipped, total_results = json.load(f)\n",
    "    return skipped, total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to disk\n",
    "def save_to_disk(total_results: dict, skipped: int, append_previous_results: str = None, name: str = RAW_SEARCH_STRING):\n",
    "    total_results_combined = total_results\n",
    "    skipped_combined = skipped\n",
    "\n",
    "    if append_previous_results is not None:\n",
    "        skipped_tmp, total_results_tmp = load_from_disk(append_previous_results)\n",
    "        skipped_combined += skipped_tmp\n",
    "        # append the newer entries to the end\n",
    "        total_results_tmp.extend(total_results_combined)\n",
    "        total_results_combined = total_results_tmp\n",
    "\n",
    "    with open(f\"{name}__{len(total_results_combined)}of680__{time.time()}\", \"w\") as f:\n",
    "        json.dump([skipped_combined, total_results_combined], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_disk(total_results, skipped, append_previous_results='transformer AND (\"2-bit\" OR \"2bit\" OR \"2 bit\" OR \"1-bit\" OR \"1bit\" OR \"1 bit\") AND (\"post-training\" OR \"post training\") AND \"quantization\" AND \"function\" -\"image compression\"__647of680__1729862542.3874462')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped, total_results = load_from_disk('transformer AND (\"2-bit\" OR \"2bit\" OR \"2 bit\" OR \"1-bit\" OR \"1bit\" OR \"1 bit\") AND (\"post-training\" OR \"post training\") AND \"quantization\" AND \"function\" -\"image compression\"__703of680__1729863140.3934956')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Postprocess results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_entries(results: list):\n",
    "    assert results[0].get(\"title\") is not None, \"The provided data must be a list of dictionaries that must contain the key 'title'\"\n",
    "    seen = []\n",
    "    unique = []\n",
    "    for item in results:\n",
    "        if item[\"title\"] in seen:\n",
    "            continue\n",
    "        elif item[\"title\"] is None:\n",
    "            print(f\"Warning: item '{item}' does not contain a title\")\n",
    "        else:\n",
    "            seen.append(item[\"title\"])\n",
    "            unique.append(item)\n",
    "    print(f\"Reduced original results from length: {len(results)} to unique items: {len(unique)}\")\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_results(results: dict, min_citations: int = 50, title_must_contain: str = None):\n",
    "    assert \"cited_by_count\" in results[0].keys(), \"The file cannot be filtered, because not all entries contain a value for the key 'cited_by_count'\"\n",
    "    output_results = []\n",
    "    for elem in results:\n",
    "        if elem[\"cited_by_count\"] >= min_citations:\n",
    "            if title_must_contain is None:\n",
    "                output_results.append(elem)\n",
    "            elif title_must_contain.lower() in elem[\"title\"].lower():\n",
    "                output_results.append(elem)\n",
    "    return output_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced original results from length: 703 to unique items: 633\n"
     ]
    }
   ],
   "source": [
    "deduplicated_results = remove_duplicate_entries(total_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_citations = 20\n",
    "filtered_results = filter_results(deduplicated_results, min_citations)\n",
    "len(filtered_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Zeroquant: Efficient and affordable post-training quantization for large-scale transformers',\n",
       "  'title_link': 'https://proceedings.neurips.cc/paper_files/paper/2022/hash/adf7fa39d65e2983d724ff7da57f00ac-Abstract-Conference.html',\n",
       "  'id': 'M1H30TzgocoJ',\n",
       "  'cited_by_count': 289},\n",
       " {'title': 'I-vit: Integer-only quantization for efficient vision transformer inference',\n",
       "  'title_link': 'http://openaccess.thecvf.com/content/ICCV2023/html/Li_I-ViT_Integer-only_Quantization_for_Efficient_Vision_Transformer_Inference_ICCV_2023_paper.html',\n",
       "  'id': 'wA-a8sZKDhMJ',\n",
       "  'cited_by_count': 73},\n",
       " {'title': 'Q-vit: Accurate and fully quantized low-bit vision transformer',\n",
       "  'title_link': 'https://proceedings.neurips.cc/paper_files/paper/2022/hash/deb921bff461a7b0a5c344a4871e7101-Abstract-Conference.html',\n",
       "  'id': 'pYjd1jUZ5TYJ',\n",
       "  'cited_by_count': 73},\n",
       " {'title': 'Mr. biq: Post-training non-uniform quantization based on minimizing the reconstruction error',\n",
       "  'title_link': 'http://openaccess.thecvf.com/content/CVPR2022/html/Jeon_Mr.BiQ_Post-Training_Non-Uniform_Quantization_Based_on_Minimizing_the_Reconstruction_Error_CVPR_2022_paper.html',\n",
       "  'id': 'LGScuzy99a8J',\n",
       "  'cited_by_count': 40},\n",
       " {'title': 'Billm: Pushing the limit of post-training quantization for llms',\n",
       "  'title_link': 'https://arxiv.org/abs/2402.04291',\n",
       "  'id': 'oTlxs9Jcl0sJ',\n",
       "  'cited_by_count': 32},\n",
       " {'title': 'Towards efficient post-training quantization of pre-trained language models',\n",
       "  'title_link': 'https://proceedings.neurips.cc/paper_files/paper/2022/hash/096347b4efc264ae7f07742fea34af1f-Abstract-Conference.html',\n",
       "  'id': 'tN16y3kVeNYJ',\n",
       "  'cited_by_count': 55},\n",
       " {'title': 'Vaqf: Fully automatic software-hardware co-design framework for low-bit vision transformer',\n",
       "  'title_link': 'https://arxiv.org/abs/2201.06618',\n",
       "  'id': 'Im7_w0q2SbkJ',\n",
       "  'cited_by_count': 51},\n",
       " {'title': 'Outlier suppression: Pushing the limit of low-bit transformer language models',\n",
       "  'title_link': 'https://proceedings.neurips.cc/paper_files/paper/2022/hash/6f6db140de9c9f111b12ef8a216320a9-Abstract-Conference.html',\n",
       "  'id': 'ZtpuMfg9oo8J',\n",
       "  'cited_by_count': 92},\n",
       " {'title': 'Auto-vit-acc: An fpga-aware automatic acceleration framework for vision transformer with mixed-scheme quantization',\n",
       "  'title_link': 'https://ieeexplore.ieee.org/abstract/document/10035108/',\n",
       "  'id': 'h1rQeGWkXbIJ',\n",
       "  'cited_by_count': 51},\n",
       " {'title': 'Zeroquant-v2: Exploring post-training quantization in llms from comprehensive study to low rank compensation',\n",
       "  'title_link': 'https://arxiv.org/abs/2303.08302',\n",
       "  'id': 'vRJymvaFeV0J',\n",
       "  'cited_by_count': 36},\n",
       " {'title': 'Qdrop: Randomly dropping quantization for extremely low-bit post-training quantization',\n",
       "  'title_link': 'https://arxiv.org/abs/2203.05740',\n",
       "  'id': '8q2l06dbGZsJ',\n",
       "  'cited_by_count': 118},\n",
       " {'title': 'Ant: Exploiting adaptive numerical data type for low-bit deep neural network quantization',\n",
       "  'title_link': 'https://ieeexplore.ieee.org/abstract/document/9923832/',\n",
       "  'id': 'vb97hRoe7hsJ',\n",
       "  'cited_by_count': 32},\n",
       " {'title': 'Gpt3. int8 (): 8-bit matrix multiplication for transformers at scale',\n",
       "  'title_link': 'https://proceedings.neurips.cc/paper_files/paper/2022/hash/c3ba4962c05c49636d4c6206a97e9c8a-Abstract-Conference.html',\n",
       "  'id': '2NM1BuhHURsJ',\n",
       "  'cited_by_count': 734},\n",
       " {'title': 'Bitnet: Scaling 1-bit transformers for large language models',\n",
       "  'title_link': 'https://arxiv.org/abs/2310.11453',\n",
       "  'id': 'rY4err_Kw_cJ',\n",
       "  'cited_by_count': 55},\n",
       " {'title': 'Quip: 2-bit quantization of large language models with guarantees',\n",
       "  'title_link': 'https://proceedings.neurips.cc/paper_files/paper/2023/hash/0df38cd13520747e1e64e5b123a78ef8-Abstract-Conference.html',\n",
       "  'id': 'b0_oT2nHOMkJ',\n",
       "  'cited_by_count': 86},\n",
       " {'title': 'Accelerating attention through gradient-based learned runtime pruning',\n",
       "  'title_link': 'https://dl.acm.org/doi/abs/10.1145/3470496.3527423',\n",
       "  'id': 'lBcEaeWHHUkJ',\n",
       "  'cited_by_count': 34},\n",
       " {'title': 'Norm tweaking: High-performance low-bit quantization of large language models',\n",
       "  'title_link': 'https://ojs.aaai.org/index.php/AAAI/article/view/29815',\n",
       "  'id': '7K_-DYAGyvgJ',\n",
       "  'cited_by_count': 24},\n",
       " {'title': 'Optimal brain compression: A framework for accurate post-training quantization and pruning',\n",
       "  'title_link': 'https://proceedings.neurips.cc/paper_files/paper/2022/hash/1caf09c9f4e6b0150b06a07e77f2710c-Abstract-Conference.html',\n",
       "  'id': 'szf8IM6W6R4J',\n",
       "  'cited_by_count': 169},\n",
       " {'title': 'Flexround: Learnable rounding based on element-wise division for post-training quantization',\n",
       "  'title_link': 'https://proceedings.mlr.press/v202/lee23h.html',\n",
       "  'id': 'LiYzXZ3i0XoJ',\n",
       "  'cited_by_count': 21},\n",
       " {'title': 'Quarot: Outlier-free 4-bit inference in rotated llms',\n",
       "  'title_link': 'https://arxiv.org/abs/2404.00456',\n",
       "  'id': 'fgdZvS1a_DQJ',\n",
       "  'cited_by_count': 29},\n",
       " {'title': 'Kivi: A tuning-free asymmetric 2bit quantization for kv cache',\n",
       "  'title_link': 'https://arxiv.org/abs/2402.02750',\n",
       "  'id': 'ddvel63pcjMJ',\n",
       "  'cited_by_count': 22},\n",
       " {'title': 'The case for 4-bit precision: k-bit inference scaling laws',\n",
       "  'title_link': 'https://proceedings.mlr.press/v202/dettmers23a',\n",
       "  'id': 'VhdKmOrSDjQJ',\n",
       "  'cited_by_count': 140},\n",
       " {'title': 'Loftq: Lora-fine-tuning-aware quantization for large language models',\n",
       "  'title_link': 'https://arxiv.org/abs/2310.08659',\n",
       "  'id': '3wQ-ey6iLsAJ',\n",
       "  'cited_by_count': 87},\n",
       " {'title': 'Qllm: Accurate and efficient low-bitwidth quantization for large language models',\n",
       "  'title_link': 'https://arxiv.org/abs/2310.08041',\n",
       "  'id': '0Dq2wJ8OF9oJ',\n",
       "  'cited_by_count': 34},\n",
       " {'title': 'Alphatuning: Quantization-aware parameter-efficient adaptation of large-scale pre-trained language models',\n",
       "  'title_link': 'https://arxiv.org/abs/2210.03858',\n",
       "  'id': '9kddTDnX5gkJ',\n",
       "  'cited_by_count': 30},\n",
       " {'title': 'A survey of techniques for optimizing transformer inference',\n",
       "  'title_link': 'https://www.sciencedirect.com/science/article/pii/S1383762123001698',\n",
       "  'id': 'eR3vo3-uWcgJ',\n",
       "  'cited_by_count': 38},\n",
       " {'title': 'Extreme compression of large language models via additive quantization',\n",
       "  'title_link': 'https://arxiv.org/abs/2401.06118',\n",
       "  'id': 'MPm3IDJfl7wJ',\n",
       "  'cited_by_count': 30},\n",
       " {'title': 'Optimal clipping and magnitude-aware differentiation for improved quantization-aware training',\n",
       "  'title_link': 'https://proceedings.mlr.press/v162/sakr22a.html',\n",
       "  'id': 'eW3c1fI6tEYJ',\n",
       "  'cited_by_count': 35},\n",
       " {'title': 'The era of 1-bit llms: All large language models are in 1.58 bits',\n",
       "  'title_link': 'https://arxiv.org/abs/2402.17764',\n",
       "  'id': 'GI2nY7Vp2eoJ',\n",
       "  'cited_by_count': 93},\n",
       " {'title': 'Pruning vs quantization: which is better?',\n",
       "  'title_link': 'https://proceedings.neurips.cc/paper_files/paper/2023/hash/c48bc80aa5d3cbbdd712d1cc107b8319-Abstract-Conference.html',\n",
       "  'id': 'VkDaEawlRfwJ',\n",
       "  'cited_by_count': 25},\n",
       " {'title': 'Omniquant: Omnidirectionally calibrated quantization for large language models',\n",
       "  'title_link': 'https://arxiv.org/abs/2308.13137',\n",
       "  'id': 'nPjMLgOsAfAJ',\n",
       "  'cited_by_count': 103},\n",
       " {'title': 'Lut-gemm: Quantized matrix multiplication based on luts for efficient inference in large-scale generative language models',\n",
       "  'title_link': 'https://arxiv.org/abs/2206.09557',\n",
       "  'id': 'zwplhYAy3psJ',\n",
       "  'cited_by_count': 92},\n",
       " {'title': 'Revisiting the parameter efficiency of adapters from the perspective of precision redundancy',\n",
       "  'title_link': 'http://openaccess.thecvf.com/content/ICCV2023/html/Jie_Revisiting_the_Parameter_Efficiency_of_Adapters_from_the_Perspective_of_ICCV_2023_paper.html',\n",
       "  'id': 'Veq3mAkAmIEJ',\n",
       "  'cited_by_count': 21},\n",
       " {'title': 'Pb-llm: Partially binarized large language models',\n",
       "  'title_link': 'https://arxiv.org/abs/2310.00034',\n",
       "  'id': 'mZnxHQtv7VcJ',\n",
       "  'cited_by_count': 28},\n",
       " {'title': 'Accurate lora-finetuning quantization of llms via information retention',\n",
       "  'title_link': 'https://arxiv.org/abs/2402.05445',\n",
       "  'id': 'n9_1W7Mc-xAJ',\n",
       "  'cited_by_count': 23},\n",
       " {'title': 'Vitality: Unifying low-rank and sparse approximation for vision transformer acceleration with a linear taylor attention',\n",
       "  'title_link': 'https://ieeexplore.ieee.org/abstract/document/10071081/',\n",
       "  'id': 'e-AVqsA405sJ',\n",
       "  'cited_by_count': 39},\n",
       " {'title': 'Efficient quantized sparse matrix operations on tensor cores',\n",
       "  'title_link': 'https://ieeexplore.ieee.org/abstract/document/10046057/',\n",
       "  'id': 'CUlHKMkgfAUJ',\n",
       "  'cited_by_count': 29},\n",
       " {'title': 'Bibert: Accurate fully binarized bert',\n",
       "  'title_link': 'https://arxiv.org/abs/2203.06390',\n",
       "  'id': '220arbo05FAJ',\n",
       "  'cited_by_count': 100},\n",
       " {'title': 'Transhash: Transformer-based hamming hashing for efficient image retrieval',\n",
       "  'title_link': 'https://dl.acm.org/doi/abs/10.1145/3512527.3531405',\n",
       "  'id': 'NzLBvGCeDrYJ',\n",
       "  'cited_by_count': 42},\n",
       " {'title': 'With shared microexponents, a little shifting goes a long way',\n",
       "  'title_link': 'https://dl.acm.org/doi/abs/10.1145/3579371.3589351',\n",
       "  'id': 'tB0tY_-g6qQJ',\n",
       "  'cited_by_count': 31},\n",
       " {'title': 'Parameter-efficient fine-tuning for large models: A comprehensive survey',\n",
       "  'title_link': 'https://arxiv.org/abs/2403.14608',\n",
       "  'id': '-Y8JuxIyxIQJ',\n",
       "  'cited_by_count': 119},\n",
       " {'title': 'Gear: An efficient kv cache compression recipefor near-lossless generative inference of llm',\n",
       "  'title_link': 'https://arxiv.org/abs/2403.05527',\n",
       "  'id': 'h48eVYF__7wJ',\n",
       "  'cited_by_count': 33},\n",
       " {'title': 'Fast: Dnn training under variable precision block floating point with stochastic rounding',\n",
       "  'title_link': 'https://ieeexplore.ieee.org/abstract/document/9773221/',\n",
       "  'id': 'MJZ7IjIZM3oJ',\n",
       "  'cited_by_count': 56},\n",
       " {'title': 'A survey of quantization methods for efficient neural network inference',\n",
       "  'title_link': 'https://www.taylorfrancis.com/chapters/edit/10.1201/9781003162810-13/survey-quantization-methods-efficient-neural-network-inference-amir-gholami-sehoon-kim-zhen-dong-zhewei-yao-michael-mahoney-kurt-keutzer',\n",
       "  'id': 'Qqkb0h3nbzYJ',\n",
       "  'cited_by_count': 1169},\n",
       " {'title': 'A survey on efficient inference for large language models',\n",
       "  'title_link': 'https://arxiv.org/abs/2404.14294',\n",
       "  'id': 'duKqwDtsssQJ',\n",
       "  'cited_by_count': 35},\n",
       " {'title': 'Lq-lora: Low-rank plus quantized matrix decomposition for efficient language model finetuning',\n",
       "  'title_link': 'https://arxiv.org/abs/2311.12023',\n",
       "  'id': 'UCbBoC51mxkJ',\n",
       "  'cited_by_count': 30},\n",
       " {'title': 'Llm inference unveiled: Survey and roofline model insights',\n",
       "  'title_link': 'https://arxiv.org/abs/2402.16363',\n",
       "  'id': 'u4RfTVhKko0J',\n",
       "  'cited_by_count': 30},\n",
       " {'title': 'Enable deep learning on mobile devices: Methods, systems, and applications',\n",
       "  'title_link': 'https://dl.acm.org/doi/abs/10.1145/3486618',\n",
       "  'id': 'B5HXaxbAB_cJ',\n",
       "  'cited_by_count': 103},\n",
       " {'title': \"Bringing AI to edge: From deep learning's perspective\",\n",
       "  'title_link': 'https://www.sciencedirect.com/science/article/pii/S0925231221016428',\n",
       "  'id': 'xG3kTPM2dMkJ',\n",
       "  'cited_by_count': 130},\n",
       " {'title': 'A survey of resource-efficient llm and multimodal foundation models',\n",
       "  'title_link': 'https://arxiv.org/abs/2401.08092',\n",
       "  'id': '5sm8TgDYkeIJ',\n",
       "  'cited_by_count': 57},\n",
       " {'title': 'Efficient large language models: A survey',\n",
       "  'title_link': 'https://arxiv.org/abs/2312.03863',\n",
       "  'id': 'ok-1VecpDZMJ',\n",
       "  'cited_by_count': 83},\n",
       " {'title': 'Join the high accuracy club on imagenet with a binary neural network ticket',\n",
       "  'title_link': 'https://arxiv.org/abs/2211.12933',\n",
       "  'id': 'M_mFdJIlJQIJ',\n",
       "  'cited_by_count': 20},\n",
       " {'title': 'Hardware approximate techniques for deep neural network accelerators: A survey',\n",
       "  'title_link': 'https://dl.acm.org/doi/abs/10.1145/3527156',\n",
       "  'id': 'X7-Fu3D9-GQJ',\n",
       "  'cited_by_count': 97},\n",
       " {'title': 'Seed-TTS: A Family of High-Quality Versatile Speech Generation Models',\n",
       "  'title_link': 'https://arxiv.org/abs/2406.02430',\n",
       "  'id': 'zmNRS52SFCEJ',\n",
       "  'cited_by_count': 23},\n",
       " {'title': 'Edgemoe: Fast on-device inference of moe-based large language models',\n",
       "  'title_link': 'https://arxiv.org/abs/2308.14352',\n",
       "  'id': 'EfiwOPmNFeUJ',\n",
       "  'cited_by_count': 39},\n",
       " {'title': 'Structured pruning for efficient generative pre-trained language models',\n",
       "  'title_link': 'https://aclanthology.org/2023.findings-acl.692/',\n",
       "  'id': 'gPQjRmtOVH0J',\n",
       "  'cited_by_count': 23},\n",
       " {'title': 'Pruning vs XNOR-Net: A comprehensive study of deep learning for audio classification on edge-devices',\n",
       "  'title_link': 'https://ieeexplore.ieee.org/abstract/document/9672158/',\n",
       "  'id': 'Q6kOy9yc65QJ',\n",
       "  'cited_by_count': 21},\n",
       " {'title': 'Computational complexity evaluation of neural network applications in signal processing',\n",
       "  'title_link': 'https://arxiv.org/abs/2206.12191',\n",
       "  'id': 'nnhhRThRJ-4J',\n",
       "  'cited_by_count': 50},\n",
       " {'title': 'Relu strikes back: Exploiting activation sparsity in large language models',\n",
       "  'title_link': 'https://arxiv.org/abs/2310.04564',\n",
       "  'id': '2sM30rDNoU0J',\n",
       "  'cited_by_count': 41},\n",
       " {'title': '[PDF][PDF] Benchmarking public large language model',\n",
       "  'title_link': 'https://opus4.kobv.de/opus4-haw/files/4593/I001854150Thesis.pdf',\n",
       "  'id': 'AzH0O1IK4pEJ',\n",
       "  'cited_by_count': 20},\n",
       " {'title': 'Neural inference at the frontier of energy, space, and time',\n",
       "  'title_link': 'https://www.science.org/doi/abs/10.1126/science.adh1174',\n",
       "  'id': 'pW1OlVeWCcEJ',\n",
       "  'cited_by_count': 47},\n",
       " {'title': 'Efficient and effective text encoding for chinese llama and alpaca',\n",
       "  'title_link': 'https://arxiv.org/abs/2304.08177',\n",
       "  'id': 'MvhRbsqnhGgJ',\n",
       "  'cited_by_count': 214},\n",
       " {'title': '[HTML][HTML] Deep neural networks compression: A comparative survey and choice recommendations',\n",
       "  'title_link': 'https://www.sciencedirect.com/science/article/pii/S0925231222014643',\n",
       "  'id': '-7ukhpAauHgJ',\n",
       "  'cited_by_count': 59},\n",
       " {'title': 'Structured binary neural networks for image recognition',\n",
       "  'title_link': 'https://link.springer.com/article/10.1007/s11263-022-01638-0',\n",
       "  'id': 'ARmuOep3jWsJ',\n",
       "  'cited_by_count': 23}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Write to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pandas dataframe to create excel\n",
    "filtered_df = pd.DataFrame(filtered_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_excel(f\"{RAW_SEARCH_STRING}__min_citations_{min_citations}__{time.time()}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "black"
         },
         "textinfo": "value+percent initial",
         "type": "funnel",
         "x": [
          757,
          688,
          64,
          50,
          46,
          43,
          35,
          15
         ],
         "y": [
          "Total Search Results",
          "After 2022",
          ">20 Citations",
          "No Quantization Function",
          "No Performance Tests",
          "No Scalability Test >7B Parameters",
          "No Open-Source Code",
          "Not Applicable for Ternary or PTQ"
         ]
        }
       ],
       "layout": {
        "plot_bgcolor": "white",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"d0730fca-e5b9-4fce-b7fc-9c8514b08616\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d0730fca-e5b9-4fce-b7fc-9c8514b08616\")) {                    Plotly.newPlot(                        \"d0730fca-e5b9-4fce-b7fc-9c8514b08616\",                        [{\"marker\":{\"color\":\"black\"},\"textinfo\":\"value+percent initial\",\"x\":[757,688,64,50,46,43,35,15],\"y\":[\"Total Search Results\",\"After 2022\",\"\\u003e20 Citations\",\"No Quantization Function\",\"No Performance Tests\",\"No Scalability Test \\u003e7B Parameters\",\"No Open-Source Code\",\"Not Applicable for Ternary or PTQ\"],\"type\":\"funnel\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"plot_bgcolor\":\"white\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d0730fca-e5b9-4fce-b7fc-9c8514b08616');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize results\n",
    "import plotly.express as px\n",
    "from plotly import graph_objects as go\n",
    "#title = '''(transformer OR llm) AND \n",
    "#(extreme OR low bit OR 8-bit OR 4-bit OR 2-bit OR 1-bit) \n",
    "#AND \"quantization function\"'''\n",
    "fig = go.Figure(\n",
    "    go.Funnel(\n",
    "        x=[757, #total\n",
    "           688, #After 2022\n",
    "           len(filtered_results), # > 20 citations\n",
    "           50, #No quantization function =14\n",
    "           46, # No performance tests =4\n",
    "           43, #Scalability not proven >7B =3 \n",
    "           35, #No open-source code =8\n",
    "           15 #Not applicable =20\n",
    "           ], \n",
    "        y=[\"Total Search Results\", \"After 2022\", \">20 Citations\", \"No Quantization Function\", \"No Performance Tests\", \"No Scalability Test >7B Parameters\", \"No Open-Source Code\", \"Not Applicable for Ternary or PTQ\"], \n",
    "        textinfo = \"value+percent initial\",\n",
    "        marker={\"color\": \"black\"}\n",
    "    )\n",
    ")\n",
    "fig.update_layout({\"plot_bgcolor\": \"white\"})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_excel = pd.read_excel(\"transformer-and-2-bit-etc/min_citations_20__1729864347.3632069.xlsx.xlsx\", header=0)\n",
    "old_excel = pd.read_excel('(transformer OR llm) AND (extreme OR low bit OR 8-bit OR 4-bit OR 2-bit OR 1-bit) AND \"quantization function\"__1729502211.5505743.xlsx', sheet_name=\"Sheet1\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index so it aligns with the respective row count\n",
    "new_excel = new_excel.reset_index()\n",
    "old_excel = old_excel.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Unnamed: 0', 'title', 'title_link', 'id', 'cited_by_count',\n",
       "       'Exclusion', 'Reason', 'Notes', 'Quantization Function'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Unnamed: 0', 'title', 'title_link', 'id', 'cited_by_count',\n",
       "       'Exclusion', 'Reason', 'Notes', 'Quantization Function'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_excel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_excel.loc[0] = new_excel.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                               0\n",
       "title                    Q-vit: Accurate and fully quantized low-bit vi...\n",
       "title_link               https://proceedings.neurips.cc/paper_files/pap...\n",
       "id                                                            pYjd1jUZ5TYJ\n",
       "cited_by_count                                                          73\n",
       "Exclusion                                                               No\n",
       "Reason                                                                 NaN\n",
       "Notes                                                                  NaN\n",
       "Quantization Function                                                  NaN\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_excel.loc[2][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = old_excel[old_excel[\"title\"] == 'Q-vit: Accurate and fully quantized low-bit vision transformer']\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Q-vit: Accurate and fully quantized low-bit vi...\n",
      "Name: title, dtype: object\n",
      "17    Towards efficient post-training quantization o...\n",
      "Name: title, dtype: object\n",
      "8    Zeroquant-v2: Exploring post-training quantiza...\n",
      "Name: title, dtype: object\n",
      "5    Ant: Exploiting adaptive numerical data type f...\n",
      "Name: title, dtype: object\n",
      "14    Loftq: Lora-fine-tuning-aware quantization for...\n",
      "Name: title, dtype: object\n",
      "30    A survey of techniques for optimizing transfor...\n",
      "Name: title, dtype: object\n",
      "7    The era of 1-bit llms: All large language mode...\n",
      "Name: title, dtype: object\n",
      "23    Revisiting the parameter efficiency of adapter...\n",
      "Name: title, dtype: object\n",
      "12    Accurate lora-finetuning quantization of llms ...\n",
      "Name: title, dtype: object\n",
      "34    Bibert: Accurate fully binarized bert\n",
      "Name: title, dtype: object\n",
      "20    With shared microexponents, a little shifting ...\n",
      "Name: title, dtype: object\n",
      "54    Fast: Dnn training under variable precision bl...\n",
      "Name: title, dtype: object\n",
      "27    A survey of quantization methods for efficient...\n",
      "Name: title, dtype: object\n",
      "36    Lq-lora: Low-rank plus quantized matrix decomp...\n",
      "Name: title, dtype: object\n",
      "55    Bringing AI to edge: From deep learning's pers...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for idx, new_row in new_excel.iterrows():\n",
    "    # search if the title exists in the old excel and insert the row of the old excel\n",
    "    new_title = new_row[\"title\"]\n",
    "    old_row = old_excel[old_excel[\"title\"] == new_title]\n",
    "    \n",
    "    if len(old_row) == 1: #if there was a match\n",
    "        print(old_row[\"title\"])\n",
    "        # try:\n",
    "        #     new_excel.loc[idx] = old_row.loc[0][1:]\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Couldnt append row {old_row} because of error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scholar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
